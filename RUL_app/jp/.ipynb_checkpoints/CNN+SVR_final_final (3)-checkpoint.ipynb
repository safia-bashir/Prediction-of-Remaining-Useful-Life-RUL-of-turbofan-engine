{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGqDEJCbAnLc"
   },
   "source": [
    "## RUL prediction using 1D CNN\n",
    "\n",
    "In this notebook, we will use 1D CNN to predict RUL of NASA's turbofan engine dataset FD001. We will show the implementation without going into the theory of CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "IpuHu1IaAnLf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models \n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pflcws74AnLh",
    "outputId": "e510ede4-3a3a-4ab5-acaa-2477dfd92a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version:  2.11.0\n",
      "Numpy version:  1.23.4\n",
      "Pandas version:  1.5.1\n",
      "Scikit-learn version:  1.1.3\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version: \", tf.__version__)\n",
    "print(\"Numpy version: \", np.__version__)\n",
    "print(\"Pandas version: \", pd.__version__)\n",
    "print(\"Scikit-learn version: \", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOuYW07fyzbP",
    "outputId": "b723b1c0-ea32-43da-9e9e-e9bb3815c61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vTN3p-5yAnLj"
   },
   "outputs": [],
   "source": [
    "def process_targets(data_length, early_rul = None):\n",
    "    \"\"\" \n",
    "    Takes datalength and earlyrul as input and \n",
    "    creates target rul.\n",
    "    \"\"\"\n",
    "    if early_rul == None:\n",
    "        return np.arange(data_length-1, -1, -1)\n",
    "    else:\n",
    "        early_rul_duration = data_length - early_rul\n",
    "        if early_rul_duration <= 0:\n",
    "            return np.arange(data_length-1, -1, -1)\n",
    "        else:\n",
    "            return np.append(early_rul*np.ones(shape = (early_rul_duration,)), np.arange(early_rul-1, -1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UaiLACtYAnLk"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets \n",
    "    from input_data and target_data.\n",
    "    \n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "    \n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is \n",
    "    produced as output.**\n",
    "    \n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of \n",
    "               29 data points between two consecutive batches.\n",
    "        \n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YtUZI0EsAnLl"
   },
   "outputs": [],
   "source": [
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \"\"\" This function takes test data for an engine as first input. The next two inputs\n",
    "    window_length and shift are same as other functins. \n",
    "    \n",
    "    Finally it takes num_test_windows as the last input. num_test_windows sets how many examplles we\n",
    "    want from test data (from last). By default it extracts only the last example.\n",
    "    \n",
    "    The function return last examples and number of last examples (a scaler) as output. \n",
    "    We need the second output later. If we are extracting more than 1 last examples, we have to \n",
    "    average their prediction results. The second scaler halps us do just that.\n",
    "    \"\"\"\n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eke1gvYAnLm"
   },
   "source": [
    "In the following cell, we will apply `MinMaxScaling` to the full trianing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAwcicd4AnLm",
    "outputId": "2c8f9cf7-a6d1-4b73-ae52-b4708615ed77"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..data/train_FD001.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcycle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mop3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor2\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor6\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor7\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor8\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      2\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor9\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor10\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor11\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor12\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor13\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor15\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor16\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor17\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor18\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor19\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m          ,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor20\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensor21\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m train_data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m..data/train_FD001.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43ms+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m   \n\u001b[1;32m      5\u001b[0m test_data \u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/test_FD001.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,names\u001b[38;5;241m=\u001b[39mcolumns) \n\u001b[1;32m      6\u001b[0m true_rul \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/RUL_FD001.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms+\u001b[39m\u001b[38;5;124m\"\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/sa/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..data/train_FD001.txt'"
     ]
    }
   ],
   "source": [
    "columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\"]\n",
    "train_data=pd.read_csv(\"..data/train_FD001.txt\", sep= \"\\s+\", header = None,names=columns)   \n",
    "test_data =pd.read_csv(\"../data/test_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "true_rul = pd.read_csv(\"../data/RUL_FD001.txt\", sep= \"\\s+\", header = None) \n",
    "\n",
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125            \n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# How many test windows to take for each engine. If set to 1 (this is the default), only last window of test data for \n",
    "# each engine is taken. If set to a different number, that many windows from last are taken. \n",
    "# Final output is the average output of all windows.\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped =['id','op1','op2','op3', 'sensor1', 'sensor5', 'sensor6','sensor7','sensor10',\n",
    "                 'sensor16', 'sensor18', 'sensor19']\n",
    "\n",
    "train_data_first_column = train_data['id']\n",
    "test_data_first_column = test_data['id']\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_data_first_column, train_data])\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "# Process training and test data sepeartely as number of engines in training and test set may be different.\n",
    "# As we are doing scaling for full dataset, we are not bothered by different number of engines in training and test set.\n",
    "\n",
    "# Process trianing data\n",
    "for i in np.arange(1, num_train_machines + 1):\n",
    "    temp_train_data = train_data[train_data[0] == i].drop(columns = [0]).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from training data\n",
    "    if (len(temp_train_data) < window_length):\n",
    "        print(\"Train engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "        \n",
    "    temp_train_targets = process_targets(data_length = temp_train_data.shape[0], early_rul = early_rul)\n",
    "    data_for_a_machine, targets_for_a_machine = process_input_data_with_targets(temp_train_data, temp_train_targets, \n",
    "                                                                                window_length = window_length, shift = shift)\n",
    "    \n",
    "    processed_train_data.append(data_for_a_machine)\n",
    "    processed_train_targets.append(targets_for_a_machine)\n",
    "\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Process test data\n",
    "for i in np.arange(1, num_test_machines + 1):\n",
    "    temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "    \n",
    "    # Verify if data of given window length can be extracted from test data\n",
    "    if (len(temp_test_data) < window_length):\n",
    "        print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "        raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                             \"Try decreasing window length.\")\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                             num_test_windows = num_test_windows)\n",
    "    \n",
    "    processed_test_data.append(test_data_for_an_engine)\n",
    "    num_test_windows_list.append(num_windows)\n",
    "\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)\n",
    "print(\"Processed test data shape: \", processed_test_data.shape)\n",
    "print(\"True RUL shape: \", true_rul.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRxGEQhujV9G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UVvXJ78wW1W"
   },
   "source": [
    "# **Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "9DfvB5LnjWLO",
    "outputId": "541958de-b10c-47cd-bd5d-7f61e91661c9"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m126\u001b[0m\n\u001b[0;31m    clf.fit(Train,ytrain)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    " \n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets\n",
    "\n",
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows\n",
    "\n",
    "#applying every things \n",
    "columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\"]\n",
    "train_data =pd.read_csv(\"/content/drive/MyDrive/Project/data/train_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "test_data =pd.read_csv(\"/content/drive/MyDrive/Project/data/test_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "true_rul = pd.read_csv(\"/content/drive/MyDrive/Project/data/RUL_FD001.txt\", sep= \"\\s+\", header = None) \n",
    "\n",
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125            \n",
    "\n",
    "\n",
    "#\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped =['id','op1','op2','op3', 'sensor1', 'sensor5', 'sensor6','sensor7','sensor10',\n",
    "                 'sensor16', 'sensor18', 'sensor19']\n",
    "\n",
    "\n",
    "test_data_first_column = test_data['id']\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "\n",
    "\n",
    "def process_test_data_for_multiple_engines(test_data, num_test_machines, window_length, shift, num_test_windows, true_rul):\n",
    "    processed_test_data = []\n",
    "    num_test_windows_list = []\n",
    "    \n",
    "    for i in np.arange(1, num_test_machines + 1):\n",
    "        temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "        # Verify if data of given window length can be extracted from test data\n",
    "        if (len(temp_test_data) < window_length):\n",
    "            print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "            raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                                 \"Try decreasing window length.\")\n",
    "\n",
    "        # Prepare test data\n",
    "        test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                                 num_test_windows = num_test_windows)\n",
    "\n",
    "        processed_test_data.append(test_data_for_an_engine)\n",
    "        num_test_windows_list.append(num_windows)\n",
    "\n",
    "    processed_test_data = np.concatenate(processed_test_data)\n",
    "    true_rul = true_rul[0].values\n",
    "    \n",
    "    return processed_test_data, true_rul, num_test_windows_list\n",
    "\n",
    "\n",
    "\n",
    "    data_preprocessing = Pipeline([\n",
    "    \n",
    "    ('drop_columns', pd.DataFrame(data=test_data.drop(columns=columns_to_be_dropped))),\n",
    "    ('scaler', MinMaxScaler(feature_range=(-1,1))),\n",
    "    ('process_test_data', process_test_data_for_multiple_engines(test_data, window_length, shift, num_test_windows))\n",
    "])\n",
    "    model_pipeline = Pipeline([\n",
    "    ('flatten_layer', flatten_layer_model),\n",
    "    ('regressor', best_reg_model)\n",
    "])\n",
    "    clf=Pipline([\n",
    "        (\"data_preprocessing\",data_preprocessing),\n",
    "        (\"model_pipeline\",model_pipeline)\n",
    "\n",
    "    ])\n",
    "        \n",
    "   clf.fit(Train,ytrain)\n",
    "\n",
    "\n",
    "   y_pred_class= clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7gjjoxAnLn"
   },
   "source": [
    "## Training and validation split\n",
    "\n",
    "We will take 20% of training data (sampled randomly) as our validation set. We will monitor the training of our model using the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1Zk1nq8AnLn",
    "outputId": "13abc517-76b1-4c7c-e899-3cd3d943793f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train data shape:  (14184, 30, 14)\n",
      "Processed validation data shape:  (3547, 30, 14)\n",
      "Processed train targets shape:  (14184,)\n",
      "Processed validation targets shape:  (3547,)\n"
     ]
    }
   ],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aXAoxESObb4D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJ99IZo7AnLo"
   },
   "source": [
    "## 1D CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8Cxt4h0IAnLo"
   },
   "outputs": [],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(256, 7, activation = \"relu\", input_shape = (window_length, processed_train_data.shape[2])),\n",
    "        layers.Conv1D(96, 7, activation = \"relu\"),\n",
    "        layers.Conv1D(32, 7, activation = \"relu\"),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNxfcq0cAnLo"
   },
   "source": [
    "We will use a learning rate scheduler that will decrease the learning rate after 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "dnAq5CblAnLp"
   },
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch < 10:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ToNUTgytAnLp"
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "o5Vf5nm4AnLp",
    "outputId": "9d23e71d-3cd3-4417-84b6-a1785e879fe2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/30\n",
      "222/222 - 10s - loss: 1053.7069 - val_loss: 361.3473 - lr: 0.0010 - 10s/epoch - 43ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/30\n",
      "222/222 - 1s - loss: 337.6743 - val_loss: 313.4644 - lr: 0.0010 - 911ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/30\n",
      "222/222 - 1s - loss: 281.2764 - val_loss: 272.2435 - lr: 0.0010 - 898ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/30\n",
      "222/222 - 1s - loss: 248.9463 - val_loss: 240.5777 - lr: 0.0010 - 903ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/30\n",
      "222/222 - 1s - loss: 250.4654 - val_loss: 215.7558 - lr: 0.0010 - 895ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 6/30\n",
      "222/222 - 1s - loss: 228.9520 - val_loss: 222.0050 - lr: 0.0010 - 915ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 7/30\n",
      "222/222 - 1s - loss: 217.0896 - val_loss: 205.5458 - lr: 0.0010 - 880ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 8/30\n",
      "222/222 - 1s - loss: 210.7853 - val_loss: 227.7875 - lr: 0.0010 - 897ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 9/30\n",
      "222/222 - 1s - loss: 200.3119 - val_loss: 215.8867 - lr: 0.0010 - 907ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 10/30\n",
      "222/222 - 1s - loss: 188.3385 - val_loss: 174.0850 - lr: 0.0010 - 920ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 11/30\n",
      "222/222 - 1s - loss: 160.4975 - val_loss: 158.4158 - lr: 1.0000e-04 - 842ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 12/30\n",
      "222/222 - 1s - loss: 159.0988 - val_loss: 156.8878 - lr: 1.0000e-04 - 857ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 13/30\n",
      "222/222 - 1s - loss: 155.8042 - val_loss: 154.6571 - lr: 1.0000e-04 - 868ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 14/30\n",
      "222/222 - 1s - loss: 153.9678 - val_loss: 152.4826 - lr: 1.0000e-04 - 863ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 15/30\n",
      "222/222 - 1s - loss: 153.4768 - val_loss: 152.6232 - lr: 1.0000e-04 - 859ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 16/30\n",
      "222/222 - 1s - loss: 150.4914 - val_loss: 152.1705 - lr: 1.0000e-04 - 928ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 17/30\n",
      "222/222 - 1s - loss: 147.8492 - val_loss: 153.9557 - lr: 1.0000e-04 - 920ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 18/30\n",
      "222/222 - 1s - loss: 145.8966 - val_loss: 146.1236 - lr: 1.0000e-04 - 917ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 19/30\n",
      "222/222 - 1s - loss: 143.5380 - val_loss: 140.2228 - lr: 1.0000e-04 - 938ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 20/30\n",
      "222/222 - 1s - loss: 141.2971 - val_loss: 148.3574 - lr: 1.0000e-04 - 861ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 21/30\n",
      "222/222 - 1s - loss: 138.5831 - val_loss: 136.0551 - lr: 1.0000e-04 - 865ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 22/30\n",
      "222/222 - 1s - loss: 137.3827 - val_loss: 135.8885 - lr: 1.0000e-04 - 912ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 23/30\n",
      "222/222 - 1s - loss: 134.3800 - val_loss: 132.4393 - lr: 1.0000e-04 - 898ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 24/30\n",
      "222/222 - 1s - loss: 134.3404 - val_loss: 132.1464 - lr: 1.0000e-04 - 873ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 25/30\n",
      "222/222 - 1s - loss: 131.2227 - val_loss: 128.0664 - lr: 1.0000e-04 - 894ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 26/30\n",
      "222/222 - 1s - loss: 129.6288 - val_loss: 125.6333 - lr: 1.0000e-04 - 904ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 27/30\n",
      "222/222 - 1s - loss: 127.6039 - val_loss: 125.6321 - lr: 1.0000e-04 - 893ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 28/30\n",
      "222/222 - 1s - loss: 125.0699 - val_loss: 133.0666 - lr: 1.0000e-04 - 936ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 29/30\n",
      "222/222 - 1s - loss: 123.5307 - val_loss: 122.3375 - lr: 1.0000e-04 - 888ms/epoch - 4ms/step\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 30/30\n",
      "222/222 - 1s - loss: 122.2173 - val_loss: 118.9348 - lr: 1.0000e-04 - 883ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 30,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 64, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xdAI9m_AAnLp"
   },
   "source": [
    "Why did we run the model only for 30 epochs, even though the validation loss seems to be decreasing? Well, while training this model for more epochs, we previously observed that it is possible to decrease the validation loss to a very small number. But in that case, our actual test loss is not that great. This is because our model is overfitting the validation dataset. So to get a good test performance, we should stop our training at an intermediate value of the validation loss. We chose 20 epochs as that gives a good enough test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "LmsF0kdDAnLq",
    "outputId": "24d98e75-f20a-46c2-89a7-46d0182b1d96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step\n",
      "RMSE:  16.884440236693678\n"
     ]
    }
   ],
   "source": [
    "rul_pred = model.predict(processed_test_data).reshape(-1)\n",
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine, weights = np.repeat(1/num_windows, num_windows)) \n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLbgBHGbAnLq"
   },
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "HbQLJ64YAnLq",
    "outputId": "58ff0c10-4bbf-435b-8249-5da8d0784130"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-88b70d08a785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FD001_1D_CNN_piecewise_RMSE_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRMSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.models.save_model(model, \"FD001_1D_CNN_piecewise_RMSE_\"+ str(np.round(RMSE, 4)) + \".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9Oxk9UEAnLq"
   },
   "source": [
    "We will now compute the RMSE by taking only last example of each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "1tGI79DtAnLr",
    "outputId": "dfaf80c3-04ad-4ea2-db4a-b9fe672d2d2e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0a6a08bdf1f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindices_of_last_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_test_windows_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpreds_for_last_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_for_each_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_of_last_examples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRMSE_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_rul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_for_last_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RMSE (Taking only last examples): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSE_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds_for_each_engine' is not defined"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiS5ldNZAnLr"
   },
   "source": [
    "If you are not convinced by above calculations, take a look at the last section of [this notebook](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_FD001_xgboost_piecewise_linear_degradation_model.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_qxOJarYAnLr"
   },
   "source": [
    "For CMAPSS data, along with RMSE another metric (S-score) is usually reported in literature. S-score is defined as:\n",
    "\n",
    "$$S= \\sum_{i=1}^N{s_i}$$\n",
    "\n",
    "where, \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    s_i=\n",
    "    \\begin{cases}\n",
    "      (e^{-\\frac{d_i}{13}})-1, & \\text{for}\\ d_i < 1 \\\\\n",
    "      (e^{\\frac{d_i}{10}})-1, & \\text{for}\\ d_i \\geq 1\\\\\n",
    "    \\end{cases}\n",
    "  \\end{equation}\n",
    "  $$\n",
    "  \n",
    "We can compute the S-metric as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uWPR7LlvAnLr"
   },
   "outputs": [],
   "source": [
    "def compute_s_score(rul_true, rul_pred):\n",
    "    \"\"\"\n",
    "    Both rul_true and rul_pred should be 1D numpy arrays.\n",
    "    \"\"\"\n",
    "    diff = rul_pred - rul_true\n",
    "    return np.sum(np.where(diff < 0, np.exp(-diff/13)-1, np.exp(diff/10)-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jaSXpSfxAnLr",
    "outputId": "0cbd7401-35b5-4f0e-bd1f-e273c24e766a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-score:  460.95755220329374\n"
     ]
    }
   ],
   "source": [
    "s_score = compute_s_score(true_rul, preds_for_last_example)\n",
    "print(\"S-score: \", s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "qPENUM7lAnLs",
    "outputId": "dc5c4d8c-7343-46a8-f9bc-08669b9178fd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9ebwlVX3u/a29d9WeztjnnO7T3XT3aYQG6ZZuFRQciRJAo4gvwTcOV7mYeEliYl6NGRwSctHkJnrfaDRGzU1CBDQarrmaREElGFBABQGhmYdu6PnM5+ypag/r/rFq1bSr9nz6nG738/mczz57qNprV6311FPP+q3fTxNC0EcfffTRx8mF2Go3oI8++uijj96jT+599NFHHych+uTeRx999HESok/uffTRRx8nIfrk3kcfffRxEiKx2g0AGB8fF1NTU6vdjD766KOPEwr33nvvjBBiIuy9NUHuU1NT3HPPPavdjD766KOPEwqapu2Peq9vy/TRRx99nITok3sfffTRx0mIPrn30UcffZyEWBOeexjK5TIHDhygVCqtdlNOSKRSKU455RR0XV/tpvTRRx+rgDVL7gcOHGBwcJCpqSk0TVvt5pxQEEIwOzvLgQMH2L59+2o3p48++lgFrFlbplQqMTY21if2DqBpGmNjY/27nj76+DnGmiV3oE/sXaB/7Pro4+cba5rc++gR9u+Hb31rtVvRRx99HEf0yT0Cs7Oz7Nmzhz179jA5OcnmzZud55Zl9eQ7LrjgAs444wx2797Nueeey/333++8NzAw4Pvsddddx3vf+14ArrnmGj75yU+2/kV//ddw+eXQz93fRx8/N1izE6qrjbGxMYdsr7nmGgYGBvjd3/1d5/1KpUIi0f3hu/HGGznnnHP4h3/4Bz74wQ/y3e9+t+t91qFUkn9LSzA83Pv999FHH2sOfXJvA1deeSWpVIr77ruPl7/85QwNDflIf9euXfzbv/0bU1NT3HDDDfzVX/0VlmXx0pe+lM997nPE4/HIfZ9//vl84hOfWJmGl8vy8dixPrn30cfPCU4Mcv+d3wGPZdET7NkDn/pU25sdOHCAO++8k3g8zjXXXBP6mUceeYSvfvWr/PCHP0TXdX7jN36DG2+8kXe+852R+7355pu57LLL2m5PS6hU5OP0NJx++sp8R69QKMDhw/C85612S/ro44RGU3LXNO3vgTcAx4QQuwLvfQD4JDAhhJjRZIjGp4HXAwXgSiHET3vf7NXDFVdc0VCBA9x6663ce++9nHvuuQAUi0XWr18f+tm3v/3tWJZFLpfzee5h6DgCxqvc1zo+9zm49lpYWIB+xE8ffXSMVpT7dcBngS95X9Q0bQtwEfCs5+XXAafbfy8F/sZ+7A4dKOyVQjabdf5PJBLUajXnuYorF0Lwrne9iz/7sz9rur8bb7yRF7/4xXzwgx/kt37rt/j6178OQDqdxrIsDMMAYG5ujvHx8c4arZT7iUDuMzNybqBahR7MafTRx88rmkbLCCFuB+ZC3vpL4PcAbwjGm4AvCYm7gRFN0zb2pKVrEFNTU/z0p/LG5Kc//SnPPPMMAK997Wu56aabOGaT6dzcHPv3R2bmRNM0rr32Wu6++24effRRAF796ldzww03AFL5f+1rX+MXfuEXOmuoUu7T051tfzyhIpFUm/voo4+O0FEopKZpbwIOCiEeCLy1GXjO8/yA/VrYPt6jado9mqbdM30ikE4ILr/8cubm5ti5cyef/exn2bFjBwBnnXUWH/vYx7jooos4++yz+cVf/EUOHz7ccF/pdJoPfOADzqTqpz/9ab7+9a+zZ88ezjvvPK644gpe9apXOZ//2Mc+ximnnOL8NcSJpNz75N5HH72BEKLpHzAFPGT/nwF+BAzbz/cB4/b//wa8wrPdrcA5zfb/4he/WATx8MMP173WR3twjuEb3ygECPHWt65ug1rBr/2abOvMzGq3pI8+1jyAe0QEr3Ziaj4P2A48YE/wnQL8VNO0lwAHgS2ez55iv9bHaqKv3Pvo4+cObdsyQogHhRDrhRBTQogppPXyIiHEEeCbwDs1ifOARSFEYz+ij5XHiRQtY5ry8UQmdyHg4YdXuxUnJ9b6cX3oodVugYOm5K5p2leAu4AzNE07oGnauxt8/FvA08CTwN8Cv9GTVvbRHbxx7msdJ4Ny/973YOdOePrp1W7JyYWf/Uwe1x//eLVbEo5bboEXvKD3a3I6RFNbRgjx1ibvT3n+F8Bvdt+sPnoKb7RMrQaxNZxS6GQg94O2Ezk3B6eeurptOZkwOysfeyFSPvpRGB2F97+/+30pfO978vHo0d7tswus4VF+4mBpCfbtW+1WNIBS7tWqXBy0lnE8yP2228AOW10RLC3JR3Xc++gNVJ/oRZ2Cr3wFbr65+/148Z//KR8Lhd7ut0P0yb0HWFqSa2/W7Fj2EuVa990Vua/kwXzb2+Av/mLl9q/I/US++1iLUH1Czct0CiHk3VUvz8/yMthrXvrkfgIgHo+zZ88edu3axRVXXEEh4qSpRaqN+tyVV17JTTfdFPr69u3b2bNnD7t37+bWW2913puammJmZsZ5/v3vf583vOENgD8FcFNUKqBSCJ8o5L6SxJjPw/z8yu2/r9xXBr0i9/l5qf57lLobgDvvlHfG0Cf3EwHpdJr777+fhx56CMMw+PznP+97v2J3NpUmvdM+94lPfIL777+fT33qU1x99dXdNDkc5TJs2iT/X+uTqseD3C1LKq2VQl+5R+JnPwM7w0b7UMezW3I/dMi/v17g9tvd//vkfmLhla98JU8++STf//73eeUrX8mll17KWWedRbVa5eMf/yDvfOe5vOIVZ/OFL3wBkIvD3vve93LGGWdw4YUXOqkIGuH888/n4MEVWBZQqbjk/vOu3IXok/sq4q/+Cn791zvcuFfKXY2xXpP77t3y/3y+d/vtAidEZqbVzvhbqVT49re/zSWXXALIPDIPPfQQ27dv54tf/CIDA8N86Us/YWjI5G1vezkXXXQR9913H4899hgPP/wwR48e5ayzzuKqq65q+D0rlva3XIbJSfn/zzu5VyqS4I8HufdtmTqYpnt42kavlHuvyb1YlOGZv/3b8OCDfeV+IqBYLLJnzx7OOecctm7dyrvfLUP8X/KSl7B9+3YAvvOd7/Av//Il3va2PbzpTS9ldnaWJ554gttvv523vvWtxONxNm3axGte85rI7/ngBz/Ijh07eNvb3sbv//7vO6+HpfjtKO1vpQLptAz9+nm3ZdT++8q9c1xxBYTMH7UCy5J2d0eHZq0q9x/9SP6wV78astk1Q+4nhHJfrYy/ynMPwpv2VwjBRz7yGXbvvphkUq5hAPhWGwWpP/GJT/DLv/zLfOYzn+Gqq67i3nvvBWSpv/n5eSfVb8dpf8tl0HVYv37NK/elos4znM3ulSJGRQx95d4ZhJDEft998OY3Q5PaBkGo07q8DOvWtfndvSJ35bn3akL19ttl7YFXvAIymTVD7n3l3iUuvvhivvKVv6FSKWNZ8Nhjj5PP53nVq17FV7/6VarVKocPH+a2225ruq/3vve91Go1brnlFkAW0L7++usBqFar3HDDDZ2l/a1UZG70iYk1r9w/t/R2XsadCKuv3Nck1G966in4939ve/OuDv9atWX+8z+l3z4y0if3kwm/+qu/yqmnnsU73vEi3vKWXbznPf+NSqXCm9/8Zk4//XTOOuss3vnOd3L++ec33ZemaXzkIx/hL+wY7I9+9KM8+eST7N69mxe+8IWcdtppvOMd73A+f9111/nS/h44cCB8xyeQcp8rD1EgS6W0QqpXsUuxuHLK+mQmdy+xdnBLrQ5/R767Ol/dLmLqJblbFtx1F6h03JlMf0L1REAul6t77YILLuCCCy5wnsdiMd73vj/l6qv/lFoNduyAoSH53mc/+9mm33Hdddf5nl9++eVcfvnlAAwPD/PlL385dLsrr7ySK6+8sqXf4Sj39ev9IVtrEKWqDkC5VEVfiS/wklMuJ9VWLyHE6toyP/kJ3HNPFyEpTaCO39SUXOn7wANulEgL8NoybWMteu733iuFwqtfLZ/3lfvJBSHkfCV03+9WBEq5T0zI/BxqscUaRKkmKd0q1Zp8skN4fdaVsGZM0yWN1VDu110Hf/iHK7d/1cGvvloS2ac/3dbmXSn3Xtgy5bJ799qL86OSw+3cKR/X0ITqCU3uQsg7ICGaf3YlUatBMin/7+Wit1YwPd2Cje5V7kK4CZjWGqpVTCFrxpZLK3QBWmly97LWaih3y1rZi4oi1slJuPJKuPHGthJlrbpyP3JEjoHR0d4MVmURKXXXV+6tQTRh7dlZeOSR3uQR6ga1mgwaSCaPv3I/dgyee66eR5xjV63KzqyUO6zdSdVymRIpACxzha7Y3hO00uS+Gsq9XD4+5J5MwvveJwnyb/+25c1XXbkrS2ZqqjfHSbUlJfttn9xbQCqVYnZ2tiHBK297cfE4NSoCQshIqNUg90pFXlw8KWgQQjA7O0sqlXJZXyl3WLuTqpaFibwFKpsnqC2z2uSulPtK3c56yX3HDum333lnW82D3iv366+XGZabwkvuQnRvUSpl6SX3/oRqY6joj2bFsxcX5bzYSuaBaoajR+WcSq12/C/a6i5zfl52brXGKZVKycLZaiB4lfsaJndHua+U5348lftq2TIgSSuxAsNbHT9D2mfs3Ak/+EHLm6vrXVfRMgFyP3oU3vlO+J//s4X07CrGfWrKbVCbsfo+hJH7GlHua5bcdV13VoE2wvXXwyc+IZXr8PBxaFgAtRqcdRb88dhnSX3gN/nDD2ksL7tJGFcSuZz87vPPl9FYN90EdqCNC6UivMp9rdoyHnLvK/cO4Z3MXUlyV5NMu3bBl78sj+XgYNPNVyLOXR3ylmoqHDwohc7Gje4+FTF3Aq94gqYTqpUKnHce/Pf/Dq9/fedf2wrWrC3TKl7/ennAvvvd1fl+x3KbPcCpm+RVfCXrQHihrJirrpJCJDRwQQ0IXYexMSnt16pyN03Hllkxz32lyd3rEa6mcl/pFb6K3FWUSIu1TVdiQlVFLD/7bAv7OHhQJtFTdx7dTqqWSvLioG6ZlXKPsMWWlmT05AMPdPe1reCEJ/fzzpOhym2s9u8pnLsySpw6Kr2h41U6U5H7hg0yZ9Edd8iO44PXc4/HJcH/PCv3n4cJ1ZX87ihyb7EwdE8mVAMRFOrmtGVy37zZVdrdHidF7gqZjCT2iMm3YrE3X9sKWimQ/feaph3TNO0hz2uf0DTtUU3TfqZp2r9omjbiee8PNU17UtO0xzRNu3ilGq6QSMDFF8O3v+0WzTie8JL79qxUxMeb3MfHpXofGJApVX3wKndY26tUvZ77SoWUHi9bxjBWb0IVVu6uIUju27fLMMC9e1vafCUmVNtS7ocOSeXeS3JXxwIkuUPkpKriizVB7sB1wCWB174L7BJCnA08DvwhgKZpZwG/Auy0t/mcpmldzFa0hte/Xk4srkbRcSfMlSLrykcZGjr+tsz4uJxvuOCCkGPgVe4gJ1XXMLk70TJWZ7ZMgzti5zscdJx7tgGWliRxDAycGLbM4cPwi7/oD7dqhCC5x2Lw/Oe3TO4rMaGqyH12toVAFVu5/84/v5w/4Y+6Z1nTrFfuEOm7K+V+PNbDNCV3IcTtwFzgte8IIVTPvRs4xf7/TcA/CSFMIcQzwJPAS3rY3lBccom0vDrIY9Q1vMpdm5vl1FNXR7mD7GN1fTVMuZ8AtkwnnvvMjDwWqgh9KLxxySul3IeG5PE+EWyZ++6TB6zOz4uAYiWvWt258/go94gJVS+hP/dcg+2XluSVYPNmvv3QKfyAV/TellEZYyPIfa0p92a4Cvi2/f9mwHt4D9iv1UHTtPdomnaPpmn3NAt3bIb16+Hcc1fHdy8VpBeUogSzx5/c43E3SiiUT04w5e547h10/iNHpDJqePwVu4yNrTy5nwjKXX2uU+UOktwPHoSFhYabVquudboSyh1g//4G26sY902bmM0lsTB6M6EaZss0Ue5rntw1TfswUAFubHdbIcQXhRDnCCHOmVDx113g9a+XOfNb7aNBlEqdjcXStCSIFCWYmWH7dmnLHI+UCDMzkqNi9lkMtXnLZZ7gNL724yn5fGJCBsWvxYyFHlumkzGnBo56DIUihuNB7qtwjL+/sIeP86H2yb1VgRVF7tA0YsbbpF567l7l3tB3t2Pcaxs3M583KNODcxRlyzTx3NeELRMFTdOuBN4AvF24y0gPAls8HzvFfm3F8fKXS0JtcdK+Di97GXz0o+1vVzoqQ9+Ucp+akifweIhjZUMo6HpIp6lU+AL/jV/5/8+V41ct610jq+h86FK5K7HUcA3J8VLuicSqkPvXFi/mL/i97sm9VoNrrpG3Q16EkfuuXfKxyeBThz4W6236gdyyQNMEsZhoTO62cl8Y3EKtpknlvhLRMnDiKndN0y4Bfg+4VAjh/RXfBH5F07SkpmnbgdOBH3ffzOZQx7ST5f/lsow7ffTR9rcNKvfNtgmlFsKtJILkHqXcS6QQQuM736GpJ7iaqBTL1JDz750om5bJPR6X8bMnoS1jVeNtKdIDR3Vexg859mwgQdOjj8Kf/En9RFYYuW/dKvtVE99dNWlsrLM75YPLQ+zgMZ6pbfVtnDuWZ0Ass3louSVynzXkAqaekXsbtozjua9UqK8HrYRCfgW4CzhD07QDmqa9G/gsMAh8V9O0+zVN+zyAEGIv8DXgYeBm4DeFEMclv6w6vp2Q+8GDUqiEJUusVhunn3DIPQnMzjrkfvA43K+0qtzLdmb0b32LpreNq4lSzh2w5Ur7tWJbtmUMQ66mXClyHx5eNeVuVhNtkfvPnhnkLl7G3mcy/jeUYg9m5TNNGb3gXf0ai8ml0k3I3XvTBO0f/scXN/AEO3iQF/jalV+qkiXP1oG55uQ+PMxsUf7WnpB7u9EyS/IglJ9Y+ZC6puuThRBvDXn57xp8/uPAx7tpVCfohtzVJEwYuV95pdzn174Wvm1pVpJkamoSZp9j0yb5+vEi95e/3H0eNaFqIVfj3XwzVC/LSm28Fsk9715FrXL75N6ycl9pcl9N5V6LU0FHWGVaOYIq5LQwHxg4Ko1v8EppmnKwBQu179wpO1ij7/Iod5CHanS0hUaq7e0L/hJDsh12jo/ckmCAHNtSc9y1f8q/0dVXS+X2/vfL2+nNm51x3rMJ1XaiZRZKgIGVX/m+ccKvUFVYKXJ/8MHGVmJpTp7E1OlbYGaGyUnZ71falhGidVtGkfvcHPzkoH31adWWEQK+8Y3jMgNkFlxy70S5t0zuyaRL7r2e+V5lz920i52Ui62Rh7IHCguBgdNIuXttCIWdO+U2DVIzdqvc68jdRm5ZSOUeO8iBA5477VoN/tf/kimJn/98udJx0yY/uR/nRUzFpYr9W7r72lbQJ3f85B4c6zMzjSNw5JUYUpvHYHaWREKmA1hp5b64KDtx0JapVAK/wbZlNqyziMXgW/fb5N6qcn/wQbjssqaqrBdQYaXQmXKvs2XCiNtry1Qqvc3RbFlysK9itIxVkzfjrRY7cZT7YoBtlHIPI3eVl8ULFTHTwJpR5L5unXxsd1LVWQAVIPd8HgbIsVXso1z21A5ZWJCD5EMfgj/+Y3nOX/rS3pJ7u7bMsk3uHfTvdtEnd1xyr1T8HU4IGUQwOxud2qC0KL8wtWFYntBikc2bV165BxcwQcSKalu5bxircN558O2f2LKpVeWurlLHwcbxknvXyn1mBrZtk3cdXniVO7QmH//8z2WOi2ZQ+2rXlqnV4MwzZXbFbiAElrDLFBbbI/d8Xvjb24lyh4a3uapfqj7brnK3KpKulhn0K/e8JsndehLwhEOqCKCzzpKRP8eOwcc+5oydnoRCBm0ZZVlF2TK2HVOu9sm9ZXRT5s678MFrzSwvy/3VatH54kv2BElq/ZCzg02bVl65h5G7sfc+INBfbeWu63ItwD0PZznK+tbJupf1JpvALLlKWw3kduAj9y9+US5XDIZAeZU7tMYw99zTWho/pQzatWWKRXjsMbj11tY+H4VKxU3f0Kpyt5tYIOPv/EePch97qOQDaimK3Ldskce0BeXu9dzbQbkq+0SdLVPQpC2TewQIIXfvIIGVtWU0rWFO92JOChirvPLUe2KT+8IC/Md/gGU5d4qdKnc1D+Lt3147JmqNh4rwMDaMOjs47spdCLj2WvSv/CMQuMDZyt0w4HWvky/dzCWtK3d1j3scPPdS0SV3NZDbgWPLFGrw13/tf1HBO6EKrZH7wkLTjnXbbbD9FZs4zGT7yl3t274QXX11h6k0LMuZX2m12Iljy5DxdfhDz1V5Mffyvx/dWd/WMHLXNBkS2aDjBydU2/fc5WOdLVOKywnVxZ8BIeQeWCTZ0wlVjy2Ty8Ef/RGUMuuilbs9r9RJ/24XJza533wzvPa18PjjHdsytZrsDHv2yOdecvcSepTvXspVSMUttIlxZwebNsnPr2TJPYfc19Xgt34L/uiP0ONyoIYrd409e2ByfY1v87qeK/c3vrF7V6Fnyv3woksyQVtB2TJqMVer5N6EBB55BPYdSvI3/Hr7yl11lEce4aknBV/4AnJNQrvwJl4LKPe77oILL6xvkk+5ezr87NEKghjHltP1bQ0jd2iaCbNr5V6JUO5FSe5DlTmGh4V7J64GSQS5V9CpmV0o90pFevo2uX/963DttfAf2mujJ1Tz9hjt2zJNcOaZ8vHRR4nH5dqUdgn12DG5zYteJJ+3Re5CUCoKUomK22M9C5kOH26vLe3AIfdPf1Sq1A98AONFcqVgmOduGDIc+ZKLa9zCxdSWWyR3pdybENXNN8OPu1yu1q1yd8j96DKccYYk2bBQvhVQ7urtz3M1peRwexOq6gI0P88t/1smSulIUHoio4KLZH70I+n6BINZVBPzZN0OX6uRm5MNyJcCSV2bkXuDhgcnVNtW7jYh1nnupk4W2Z+3TpYd5W4dnmUP9/GZf5707cc7xlu1r0IRKLF3113y6f7Y9gaLmGQft6orniz3BCf3HTvko30720mBanWVDyP3prZMPk+pmiBl1FxyP04LmWZm5Fga+OEtMtfvJz+JnpSn0ze+lHI35MB4yXlxFhjl8LEWO1cLyr1SkX9d25emq2a6smXMGLzvfdL7jFLu7ZJ7k9Vsqt9Ns55/umNzZ7YMcMu/Wk4z20YDW0btL7jfUOU+O0u+ZlsNpcBSmEbk3uSCpt7KZjtLymlVZJ9dYsg5r9UqlMoJBpAXxa0TBYfcv/yDrTzAHn74Y923H+8Y76pWr+pb9vFQ5L6Pbc3TD/RtmSbIZGRERA/Ifc8eaRv6lPsxV0nOHA0Z2NPTlEiRSgqfcg9byFStylvtXoVVqxh3rVhwJozUvEOocrfH47YpSaDPHo0YoEG04Ln3Kl+Gz5bpQNk4yl3LyorJqVR0KF+r5C6Em+2wBVV6Fnv51A3jiHj7toyFzn/cM+h9qT14bRkznNyDTbLCyP3oUankkaq4bkddKnddlzdVbdsytXpbRrkfDrmPLPHss9Ju/fMfvRqoTwM8OwvJpG2PdJMGwJM+enlZRg0D7KtuaZ5+oK/cW8CZZ0rDk87IXRXVPfVUmW7Ep9z35zAwyZJj+qmQnqjIPYVLGB7l7p1b+uY3ZTTdDTe0174oOAuY8nlnNlip83DlLk/11q3y5f0z2da+qAXl3qsc1T7lXuvAllmUP7wQG3DlYbcTqoVCZDZCL0wT4rEav8OneOBhndvndrat3O/kZeRMw2lm2/DYMsF8+FHkruKtC/qwe6t65IhL7laA3Hug3DtdIBwWLaPS/SpbZlt2lrk5+MpX4NGlzYwn5n3kXijI/jq5QT5vNWQ0FB5b5ic/kReUVAr2WZujlXtJ/oZO+ne7ODnI/dFHoVbrWLmPjEglMT4esGL25Zlgmgmmmdkf4lErck/bh3FMLmQaHZX936vcVS2Ea6/tzap0h9wLBWfhhCL3cOUu31Pk/uzcQPMvqdVcNddg0PZKuStyzyRMrGrTzBj17bBX/5lVXa5LSKe7t2W8OcobMK5pQjJe4R3alxkbE3z6kYva9txv4WISWoVTT+3elolS7nW2jL2eIK+P+JR7Dtk/8lZgwVIPPHddl4e//VBIjy0TVO6aJNOtSXmn+Xu/B9uNA7x76/c4dMh11NT43mjfXXdViN1jyyhL5g1vgH2lDdEpfy1bgNXa79/t4uQg90IBDh7smNy3bZP/29zsYPpgmQmmGWeG6cMhjDwzI8k9a99i2VcHTcMOhxRw4AAgw6QNA554ovuoEvurXeVuk7si8NBoGfu9oSEYiS2xf3HEt7+FBfjYxwIXnvl594UWyL3rqDK74w/qJcq1TmwZd6AWizS2ZRKJ1oxfL7k36FyWBclYmfSwwXveo/F/9u3hkDnWWsPt/d6sv5GXJ+9hbKxz5R5VpjCqQJMKLyzEB8NtmXKAyLtQ7uo3GYUFhoY68NztPpFngGpR7kwp94HhOGgaW2NyvB06BL+b+Rum1heoVt3gBjW+N260SbYbz91jy9x9t6SiPXvgmDlCIRe+36Ipf0Mn/btdnBzkDvDooz0n95kZwTizTCTmmZkNCV1Syn0wUbeDTZvg4P0zsoDwoUPcfz/88i/Lk98L9T4zA+NjQrKYsmXUhKpXjTjK3T3V21JH2L+8zre/m26S+eyVAgH8SekbsE3PbBlLtnHQsDpSNoWC5vmfxrYMtCYfWyR30wRDq8DQEOefD4IYh8utk/sRNnB/eReXlL6Bkah2P6Haqi1jK/eCNuCS+5Ej5OOyvFeumvJv0IDcr37g1/n00V+JbJ5jy7zlsq6UO0BuSZKnY8tkgdFRtlZltsWJCcF/LX6OLRvlQFPWjBrfm3qo3EVSkvv558PUlHxrfy783JfsxUtl0VfuzdEFuQvRRLkvGkxk84wPV5heDunQ09OUtLSr3D07cJR7pcLsAwc4cABe+EK5CvrJJ+HGtmtXuahWZUjb+Ih9hVC2jE3gvqRRgWgZgK3pGZ4t+Dvf44/Lxyee8LzoJOmgNVvmUHcVSlTHHzCsjpRNsaShUXPb1MiWgdaM33ZsGYgpz68AACAASURBVM2CoSHn2tHyKsRSie9wEQAXczNGpdgRuVeLFlU70WtQuUeTu2xjPjihmpWx4blKa3Hu+/fDF566kO8Xzo1sn2PLHNzXkXL39gl1YXBsmZQMR95YeoYtW+DDv2uRNhfYslX2+yC5b9xot6kH5P7kzAgzMwFyL4RXlyuW5fnp2zKtYMMGmT/bJvd2BsXCguxgkcq9mGV8tMb4hMaMOVi/g+lpSvEBUimbOD2m/aZNcHBpEAE88BN5xdmzBy69VJJ8N+p9fl5emMYHbeKylbuRCiH3gOcOsG1wlv2lDb59KnJXj4BfubdC7keiMwK2ArMcR9fKpPQqVgfKpmDGWGfXco9U7t7EV+2SexPlnsT0k3urERGmyS1czIbhErt5AMNa7ojcvZODUeRe57nbseOFWkr2XSHgyBFyKUlOKiTS29YwcldipdFciaPc8/MMDogOomU85L4s2+3YMlkB4+Mk5qfZtw/ed4WMZtjyPHkyguQ+aYe+9yJa5q7HpVDykvs+c2NoaFypYl98+8q9BWiaM6lqGO0pdxUG6SX3fF7uw7JgsTrIxGSMic0GeZGlOB9QgdPTlOIZN2/Q2JiUFOUymzcJCrU0Swxx/8/kYd69Wzb3Qx+Cp56C22/v7Cc7C5iydnsCyt0qhCh3T9DD1qFFlmqDLC66r4WSu1LuyWRjcs9JUulkVakXpXKcVMxCT9Rk528zbrRgxhlDjt5CgeOq3C0LkpT85N7i8RAlk+9wERddYBLTwCgtdUbunvMe3L6Zci9Uk1JtLC5K5Z6Utl2uFoiqCiF3IeD66+3vaaBIHeWOxVCm3J5yr9Uoe8pPBMk9m7HDkWdmZE1he5CMbBsmm40m967miey+ddcjwwwOyqzCGzeCHq+yT2wNJaNiRXaOGvHIZIS9wolP7iCPage2TBi5g+wAM09J5pvYkmZ8u1TtM/cGSqvPzEhbxkvuAHNzbErLTGMH2cwDT2bZtMldBX3aafLRS67twCH3jB1upcg9ZU/WhCl3T9DDtnVyVHmzYT4pE+rVK/dYTI6ERp67qi7T5cIMsxIjGStjJGrSO25UAiuAWk0uZhlHHpzQCVUhVlS5G7WAckdv6TfkFqvMMMELzo7Btm0YhYWO4tx9+fAj0gzUvW6fs0LZvvpPT0tyT9ieO1n3IiuEf87Cxr33uvnZWiF3A4tBw6RYbOPu1VN0BmA5Z0f5KFsmK/y33rbFpK2fYMsWP7kPDjp1PnpD7g8O8NKXyhXysRhsG11mH1Oh4ZClmquyVjoX38lB7meeCYcOkYyXe0fuD8g4xvHnDTFxplQx6jUH09OURMold5V9bmaGzfnHADjEJu5/bpzdu93N0raN2bAcXAM45J72ziaBkbbJ3bOkumpVqRH3jcet47LTqZV8+/fLjjY+LkneURTHjskrUjPlvqjIvbt8GaVKglS8jJ4QbadjVRzuU+5BW6ZalQS1UrZMrRggd8PPXtUqfPzjdVf15SVJnkPrEnDmmSRzs13bMlbg0EXbMvbdXiVOhbi8Wzt2jHxc5t7JMeD+brVxQLlff7186dzJZymLaCuqXIYYVeLUGNLlCWtZvZfLTrlIgKW8/B5HuQ/GZAcOkDvj43XkPjbmdoGuyN00yZHlwceTnH+++/LURC6U3Gs1MGsGWbpIMdEGTh5yB5Lmctvknk67itpL7tN7pd88ceY447vk7Mv0I4EEM9PTlIRRr9xnZ9l0TKaIfWb0xTwyv8FJTAZu+uegY9AqHHJP2j07oNwtj3JXnqLXltm2XhKeurgptf5LvyTHsbPo4+hRWL++aYhbcUm+161yL5UluRu6aDsdqxpHY9q8+zxoywTJqde2TLXgI3eTwEXx4YfhIx+RFYE8UE0YHInD85+PsTSLZbU/0ddIuUfaMp5zViDjrBlRce5lDKwl+xiGFMcul+WCoTe+EdZnC04++TBYFuia7JuDcXnCWiZ3215M6/IHLBXkHUIuBxo10gNxOf7smgrejJBBch8f95B7N+q5VOInnEutpvnJfUMplNzV4RtCTjasunLXNO3vNU07pmnaQ57X1mma9l1N056wH0ft1zVN0/5K07QnNU37maZpL1rJxjtQ5F6Yb5vct251y0F6Mggw86Qc1OMv2MjElFTGM08FVNzSEsVqCLnPzLB5/50AfE9/HWWhh5J7t8p9LG63R4VCpuqVu5pY8yr3DRM1DEye3SeJ/zF5k8Eb3iAfHWvm2DE5Yd0k219pWZF7d7G7ZjVBMl5FT9C2clfjaFyXqthnyyhbwe4cr7/uCl74QvjTR97ME4vrG++4VeVeEhjNlLu60AROvEPuo1K5G9UCVrF9Q9Ybsx2s9BNJ7rUAudvFNvLCjZLJz0aT+3e+I3n0He8APWEXC4mYKymXwdBkAwZj0k9peVLVVu7rMrINitzzeRjQ8miZdECdTTt5DrZskTrFsuTY8Sv3Lu42SyWe4nmAW6sEYGqTxVEmKc75z7M67YMsq5+0omhFal0HXBJ47Q+AW4UQpwO32s8BXgecbv+9B/ib3jSzCU49FRIJkvm5tsldWTLguiqzszBtr0idmMo6r08/51GBs7NUiVGuxuttmdlZ0nvvYVRf5pZ5GRoWZst0o9wzGcjU/MrdyNhhVh4Fp0K9vMo9NpBhC8+x/2n5uccfl6t0X/YynOeAX7k3yi1j57TvNtNdqaqTSlQw9Frbyl0NnDH7bsaxZWo1dz/2b7hz3yaefho+fOcvsaNwP3/8Rw1U8sIC+4bO5k7ObxwKWaw60TJO4Zjgb1DbB0688o+HRmKS3LGwOshW6LdlWiR3zznzkXvFjZJRGSLDyP366yVZvu51YOg1eVGOMNItC3RkA4Zi8jy1o9wtDNZlbXIvyQ6dy9mpBzIZ/wCemZG35JrGli3yenPwoGvLhFYtaxemyRHkzOwGT/DZ1Bb5+9X4UlCnfc0odyHE7UAwxu1NwD/a//8jcJnn9S8JibuBEU3TNvaqsZHQdTjtNJLL022R+759bugSBC78hypo1Fi3TlZoj2k1f/Kw6WlnNWCdcj9wAB57jE0jBRbLWTLknUlU7+e7IXdndSq4tkzaDrMyvQpOPvrmwLJZtvIszz4rSe3xx2WG3I0b5URTnXJvZsvYq/G6zZdRqumk9Ir8ug6V+1i64D4PXkVthiuV41x9NTz7oc8zxTP87L7oWT0xN8//Y36Zt/Hlxsq9KOpDIaPIPaDcl/L24q1BXHLvwI81i/XnPfi8znP3hBfmU+NO9qt8WSepy/6em7c3DpC7ZcG//qtcnGcYYOg0LIBhWWDY5D4oJMG1rNyVLZOsktGKLJfkQc7lYEAsy3PtvfWennb81i1b5MvPPRfiuXdTy7RU4giTrFsnfNMQU1vluNofiL9Qp30YeXe5Vj33DUIIla38CKCuW5sBbw62A/ZrddA07T2apt2jado901FljtrBmWeSXDjWMrk/+6zsA97bqVRK8uTsLMzMwqiRJ5GQM+BjmSLTubQrNezVqWo7QG6cTssYx1qNzfYquBfwIPFizvkeXZf77MaWcfLKgDuhmrFtGbOxciebZRv72f+cPP2PPSazJ2sanH66vZCpUJAjpxXP3Q6F7HZJtVnVSSaqLkl0Ystk5UF1bBnnCWCa1NAwKwnSaTnoJ5imlI9Wyf9y8CXcZ+70TyyGwDJr4eTuVbFq+6BytycHBweBiQk559BBWKl3QU5w+2hbxqPcRzY5axtyxTgbRuz8LYuBK4PNZHffLY/7JfZ9vd5krqRcBgO5z6GatLvanVA1EoKhRJ4lO8FaPleTGSHTIbaMreQVuT/zjJzL7im5a5uYnPTvY+pUeez3PRcLfhzw2DIdzKu0g64nVIUQAmi7lUKILwohzhFCnDMxEb6aqy2ceSbJhaOYLa44u+MO+fjKV/pfHxuD2WNVpnNpJgbdwTw+WmWGcTdmMIzc1Q7sNfybnieV4x7udwsOI0k0LO1Jq6gjd0e528WRPalzQ5V7JsM29nP4WJyFBXmjoVLj79hhK3e1gKkVz72glHuXtowwSOlVV7m3scpL8fe6ATszpLJlwKfcfXdbg4MkMX0TkV5Uq/DRmd+W+yfddIWqgdWRcl8ueMhd0+TFrZpoOz206fXcK6167nGSMfuYDdnB36kU+YLGhlH54dx8ICumTe7f+54UKRdcIF82mtxxeW2ZwZpUr+0qdz0hGIwXWTLtfPNLtXBbJkS5/0xW4fOTeweF2B2UShyJbfRZMgAbt+roWOw76A8ZLdq5j4YUuRe7zEHSBJ2S+1Flt9iPainjQWCL53On2K+tPM48k2StQKWitbQ44I47ZBKts8/2vz42BrMHiswwzsSYO+gnNsSYZsL1LBqRu2lCNsvmM2V8/G4e8C/lJ3zxZKuYn5dWUZ0tk5Hk7rVlvJn4HNi2jBAat90mXzrjDPm4Y4dUONYB+5S24rnbnbbbVXdmTSep12RywQ6V+0BW3iKH2jKm6T9ng4OkKGEWw1n0n74ieLh6Js8fPUyJFKLU5grVoHKP8tyL8ripRJVGwr5YtunJWp7mRZF7nS0j4gwbsiMWBiVLVddvxDQ1NozJtucW7XEQIPdbb4VzzpHzNYB73iL6SrkMhrCVe1mGLLYbLaPrgiG9wFJZnsf8snCVuyrxFLBlBgZkG1WNc3+0TBf61jQ5IiadBVEKsUE5vvYd9oeMqpDhIUOef99iwxVAp7/sm8C77P/fBXzD8/o77aiZ84BFj32zsjj1VDm4aM3LuuMOOYEYD4jNsTGYPVJmmgnGJ12yGj8lJZW7Sr4yM0MJSR4+clfq4QUvYNNmOcCCyh3CF0+2ilLJ/s5CQRKvzdwJW7mXrSaeu63cAb77XfnSjtPlsvPTT5dzkE8/aF84WvHcbXLsNl9GSSRJGQLd0Dr23DMDMTKZCFvGsurIPYnpK++nUC7DNdcIzuYB3vrCx6gRp1JskPGwrDnkHo+DpoVYFIocg8q9pBOjqq7RDrm368la3ot6wJaJXMRUSzCSlO3JZ2XkUH5iCoAN47bnbifp8pL70pIs3ffa17r70pvYaZYl0IX8UYNWm+RuL8bTE5Icl8py7OVyHnI3DKnYDh+WtwQeR2DLFrjvPvm/X7l3Qe6lEkfE+jpyJ5Nhin3sm874P24v9htK29FlhZWdUW0lFPIrwF3AGZqmHdA07d3A/wB+UdO0J4AL7ecA3wKeBp4E/hb4jRVpdRjGx+VtMc1Xqc7OypDjoCUDNrnPwTQTTGx1w8EmJhNMxzbIHv3hD8NnPkNp43YgRLkD7N7Nm98Mf/DeHOdwT6hy75TcnUWWnnS/AFoqiY7l915tTzFMuYNL7qcd+D5s3swOTV68Hn/YVhUteO5OVshulHu1KjNsGp0pd8WX6UHpp0dNqBbtC3I6jYxswQy18r70JXjyqRjX8lEyo1KBKfspDGY5Jvvf4CCahrvKtpVoGdNgMF5wQnKTemfkbnp2G1xQFmnLiATDSTlgCmnZd3NjMoRswwZ5XPLL9eR+++3StrrwQndfRtK+KEdNqJZqzhjVC4ukUu3bMoYhyX25osjdEy0Dcvyp2N4Auav6sb5omS5smdyyIC+y0eQ+689HpZT7YMaeo1ptW0YI8VYhxEYhhC6EOEUI8XdCiFkhxGuFEKcLIS4UQszZnxVCiN8UQjxPCPECIcQ9K9p6L8bGHOXejNx/8AP5+KpXhe6GmSWDGcYZP8Ul9/FxmK2NUvu3f4c/+zN47Wsp/Y9PAS6HODsA2L2bjRvhz/4yha5V68g9ne7clnHSoxQKzmQqAIaBTtk3URMVLbPFnvd+8knZ8bOH5dLU0x+4CYAnnrI7/fr1TT33YsnOI98Nudu5yJO2cq+SaKsyvaPchxJkMgHP3TOhGmbLlEr1A/yb34TTtpq8kX8lNdyY3IUAsxKX/U+FpSpyD5tQDUbL2OSuYBj2nVC7yt3z+eCCsmhyjzOckleFQnIUgPyIjIFYv97O37LsXydAMsmtt8pjqMJnZbvBIomIWBlUNl1yJ5drrxqTPaGq64KhpMlSRfb7fEFzlTvI8adyIai7aFzfXX0kYXfVbsJ3jyzJc11H7qkUU+zjyPKA71Q7yj1rk3s3xblbwMmxQhVg3bqWyf2OO+zl0iHZScfGYK6UpUqCifXuoJ+YkMl+Fn7jw9J3v+kmSqfI+MZQW0YFticS8rWALdOtcnfI3aPcMQwMLMqeQR6q3DMZUphsGJKEsmMHjqxZd8tXGB+Hx5/LyFvcVKq5526XDusqGZJNvKmkcIuOtKFsHHIf1uttGY9yD7NlzJCIiWIRJoZMNHDJPcKbr1RACNuWsb/T0EX9CtUo5W6lGEy4LGDo/o+3Cm+/V8Wkg19d77nrDKfsCdWkNM/zwzLMa3KTPK9qib+X3L/3PXjFK/x9XxWEqRSilLtwJlRZXm4vp7snAd5Q0mLJTmiWK8QkuatxMD7u1rcMKHeFsTEZ1GDEylhdrKo+uiQvKHXkrmlMGdKNVik+AIrLsj8PDdoX7zXqua89JBIk7UU8rZD7S14SXnNgLO2Wx/IG8TgLmX77Wifzl6eEootdu2Tv8c7UTk72VLk75O6pnwo4yt27dF15ikHlDrBtVI4sL7nz4IPs2Frk8WPD7sqMZp675Xajjhdm2MSbSgqHJNpRNkVbVaeHjdZtGUXuIasUSyU7PzuQGpUnOEq5OxGCAXKPnFANeu7lJIO6S/id5j1RF/J03KyLXIpU7iQYTss3VbKw/IA876MTCRKUyasiKPbAOrKU4aGH/H67bHfj81a2hKvcl5fby+nukLvGYLrMUm2AahVKVlzaMl7lrhBC7obhDhkjVqm7CLaDIzmZoqGO3IGpjAxI8Ma6q5XcQyMhqblXACcPuQPJQTkqGpF7Pg8//Wm43w4w9oNvOP977uq8OcEchJL7W94iiVylnQNJkj3y3KtV+WcYhCp3acu4L6nBHFTuAFuHZKzxGWcgyd3+IafHnuLxhQ3SklEbN/LcLXeAdLowQ5gWFkmSSZyqUe0ULy4sVjAwiQ9mWrdlsllSmJTK9QO8VIKUJjtSelQSR7EQrtxVfzO0snO/nwyL+Y6Kcy+nGdTdTmuoFa4d2jIDiVKd3RA6oVqTK0qTeo1UCgoqWVhWknt21GCAHLkAuf/HPfJzXr8d3HoCVj5iQtXsQrmrCVUDhtIVyhhOjrA6W0YhhNyVagcw4tXubJmCPA5h5D6RkSLRyxdqJffQaH2akJXAyUXuQ3JUNCL3u++WYuqVL6vCX/6lv67cM88w/t1/cp56lbv637veKpTcoT4EZ8OGjmyZ6en6Ae5bRxKYUFW2jNfyDFXu9kDYlpWjw1Hup50Gu3ezY/pODlnj5NZtdfbbULl7yLFT5W7m5IaplKeiVBudv7BUJoOcg2jZltE0kkYNM6TARKkEKeR2qTEp9VQB77q2K7ci4Sp7wwgh9yjlXk0zmPSQu62A27Zl7DuQgYTpWy1cq7k3EL59Oj627EaF4Y3wd39HftdLAciO6Da5x3w/9NYfZRkZkUVnvFDVvqIuypZS7vE45HIdKXfD0BjKyB+j6qL6JlSVCtM0NzQSOOUU/9tgk3sXazOOFIaIa1Xf9URhOCvb6E0AWsrL/jG0zk4T0oZ46QQnF7mPSNJqRO533AGxmOBlX7wS3v9++IVfgP/zf+SbH/kIY7F557NhtkxT5R4GZct4VqU0s2WEkGnq/yaQnccXahw1oerxkFU0gE+5axpkMpyakRecM89Ekvu6dXDZZezYL0NoHjd24WzcyHMvu+TYKbmrW9ZUWnMVYBudv7hcleQ+MBBtywSVO5AyROiCoVIJUsIm93WSOKI8d+eCa7jvh9kyhbzgLXyV/Uujvu2XqlmGku7xVXMO7eZ0V7bMgOG3ZbznxHd+AuSeL2hw1VXkLdlZBkYSktyL9r4Uuf8wxWteU69hjHTji7JcoWrJwdSp525ozoSkstZDlfu6db4GKnL3ErEerzWsHNUMR0ojrE8u1h0HgJGBenIv2iuhB8bsIubdVIFqAT9/5H5bhd2ZJxn65g0yt/aePXD55fDBD8KXv8zYVW9yPhtmy7Sk3IPYsEEyuUemNFPupilDNlUH9r4OEROqui4nVJspd4Bslndtv52bb5Y1vJmdlQPizW/mXH4MwG1LL3b229CWqehO7dKOlXteDoZkSutMueeqpCk6yj3Ulgl67vb3QX2fKZUgVZPHNzUoya6Zcjd0D7mHhHM+fmSIf+Yt3Da327f9cjXLYKqe3NtW7uUYMaqkE2XfmgMrxKZTT3zK3Z6UVmvjsgMa2ViRfCnh/FALnf3PxX1ZTt12h1QC88BZoWqTe1vKXbXVgKEB2dcOH7DJMozcA6ve02n5tV5yN+LVrlZVH7HWsSEdfnVKDSQwNMuXVLRUqJGkhDEqBZk3TchK4OQi93XyoEWRe8WscvcPyrwyfzPccIOsd3frrXDRRfDJT8L4OGN/8GuAnXXRw5vqecfKHXy+ezPl7rGJfXCIJCTOnVgMnYpvSXWocgfIZsla81x8sf1cKfezz2bbVIzd3M83n/Eod1XoIqytVd3NdNdhvoyS7UdK5W6TW6l1ZVPICceWcY5tyIRqULkrtR1K7tU8jIy47k4zW8YIIXePcjfttBBzpn9xy7LIMphyP6cuOJ1MqBpaGT1e85FWFLkLq0wZA10XZLMuuTsFMLIwECuSM11yn0GqHDUd44VzxxVx3hzlPjEhbZlBweJii9UU7ayQuhFjcEBucOg5ecxCbZmQlCZ//ufwm7/paW+81lGtXoUj5TEmMxFXp2yW4XjOr9wLkKboknsb/bsTnJzknguXj0/8++MUamnO+S/Ph7e/Xb6Yzcqg5g99CP7hHxjeOkw87lftChMTXSh38JF7M+WuyD2sBChE2DKAHqv4bBk1YVSn3L1SDVxy1zS47DIu5Zv84KlN8mKmNo6Q5cWq4SRDippMawZHuadj6El7wqmNC0WxUPN57oUCOFnfoiZUgZQhB1jwOJsmpCq59sjdE30VlvxMfcesp9i6aUIZg8GMS+4OSbZL7pUYRqyCHhc+5R5m+wNUS/INXdfClXsWBuJFcqbuNHYGSZph4yOsnoCvfWXNVe61GhvHy5RKMp0GuZx//iuAmlmWFcWSmhNKePigfGxFuQNcdZV0YRWMRE3mn+8wfvdIdZzJgVz4m5kMI7Elv+deEqQooa+T578d8dIJTipyN8bkQTNnwq+me//1aQB2/r+7/G/ourRo3vAGZx4mLJfZ+Hi9cte0EFUchCJ3z6Rqq+QepdxDJ1QBQ6v4VieqxSxhyt0ZxcWi/FMTUG97G29K/Ds1ofGtb3k2DmGbWg1MkXSVe4fhXSozYyoTc8sFtnHbWrBVEQMDDlEJAhnawmyZBso9WQ6QuxU+XMKqzxnJenJX3zFXdsndKdSRdn9rp+RuVuJODVrvgrIo5a7OlW5IclfdIZ+Xhy0ehwG9RM5SpaVMpnUZAx82PtR5iyItS63ita8M2ybk1WT/fuCLX5SrCiNuZ52KYobGkAxS4fBhm9wTpuuvq6tO2NUn2N6wVcQtQgg4Wptgcqi+TioAmQzDLPlsmWJRI00RfUz+gDWfFXItITkhD5o1F3413fujZTRqnHlBSOySBxMT4bed4+P1yj2VckOrIhFhy1hWdP3kpuQer8hOWafcq758GQ2VuxrN8/YksiL3c8/lRcu3s2kTfOMbNKxsUFc6rMN8GV5yd8oFllrv/IWi5rNlnBod3iQ+lkVJ8+cDSiXryb1Wk+cmZS3ByIhb89YK92cdqyzpdgQjqclFTF5bRpF7Zch5bXlB/u7BrCfSplvlnhCUW/DcXXLHZ8t4l09kExb5shubOZOQfTmMOx1yj5gIL1c115YhUKj9wAF5rEKKSoOH3JMxhoblcT50WD5m056LiYp1DKZqDEEnRWEU5uflHdfkcIS3mskwzIJfuZsyAksfTPl+00qhu0xPawyK3M35fP2bQrD3qTTPGzxGJtOY3D/9aRgern99/Xp45BH3uZPAqxnGx6U9ELBlQA74gPgG3D4e6bmrxSCBjfVYlZKH3Bsqd9UetYDJEzqmpZJceqmstFN6ZUqaGSGDIFiAoFPlrtLuJjNxcJR7652/WNJ8tgzIY2h402+aJqXYGHHc5efJkMIp6hinzEW/co/IIOhccFMecje0elvG/tysGJVX9XicpRkLSDM06CF3nwJuXX+Z1TjJWMVWpHa5O03zkbuP6L3KXfN77orcBwyLXC7p/NDpeDS5O7ZMxHmzKjFpyyhyH14AtkhyV6opYsJMWT0+cj8qv2/Ac9dDOg3//M/4ippGwEi0X6tX4cgheW4mRyJuvzMZRmpzHPF67maMdMzEyNq2TIvpyTvFyaXcN8jl0+Z8yNX0kUfYa53Gzuc1jy+78MLw1ATBiMaWyV2Z+B5bxlGDERd+x3MP1NJ0LICa/YGgLRP32zIqjjcsWsZR7iHkDnDppfIjtz1t1yJsQO6qJmbHtoy9+jOVjbvKvY3OXzDjvmgZ8ETMeJV7POs7Z8mQsENnLqW0ELBlGit3L7knU1r9hKrt2c+xzvmSZbvK0aBnzZtTLrHNOGirEseI28od3bktjAqFdMk9Vue5+8i9mpZ93jSZia0PhpDXtzvElhFCCg2vLTOeWCCdtpW78jsjyN0pOpOMkR5MEKPKkekQcgcZ/bZpU+h+vHCOUyfk/pzcZnJdxO1VJsNwZY6FBbcPl6wYqXiZREYOxr4t0waSkzJ+2FyoZ0zrP37A4+xg5/lDde+1islJ2ffUrVbL5K42DlHuUb67Wg1pPuVPh+8QiR2DXW/L1Hyr7lSNzETwHs07miPI/TWvkQttv/HgqfKFEJ/AqQtp2OmWO8yX4ZD7QNwhiXY6f8GM+2wZ8ETMeOLci7GsL9FbKt2A3IvzMDLieOmliKXq6rAoOwWkLVPnudvKf5YxXw6lhwAAIABJREFUl9zn5PFSESDgkqSaZG4VVi2OEa+i637S6sRzd8g9WaYq4vL4mCbT2gSjoyH9ydPusIuyDLbyTKgCWm6ZbdvwK/eoXPCq0HsqhpaSczzlSgyNGqlsZ+GMzlqEDpZVHzlgk/tYxIUhm62zZYpWnHTcQksaJAIJ/lYCJxe5b5TkZC7VX/0f//cnqKCz8+UjHe9fWedKgLdF7oFVqk3JfUl2GjNAlg65Ryh3PV71FT22agn0WKV+XsCr3NU67gC5J5Nw8cXwrw9soYYWrtxVdRk7TrvT2F1VRSiZSTi1YNtS7mWdTMwEXa9X7t587rG0X7nbatt7HhxyFwUYGSEWk0mmSpVwF9M5J2kPuadCyN3yKHe7Tct2laPBYc+2ypZpcKH8whfkAmtfO6oJkvFq3QIqxV1qnkfBa3UEPXeVPSObqjqvYZrMiPHQyVSg4XlzLoAez53lEHKPsmWU556KQdKdwB9IlNAy6dBtmiF0FXGLOHJQtmdyIqK/ZzIMs0gupzk3b6VynFSiEroeZSVwcpG7Sj+wHLgSC8HeH8lJ1p27Os/f3BW5B5R7U1vGTg9qBnxex3Ov+OunKhjxmrukulajTMIp/uBDmHIPWUd96aVwaD7DT3lROLmr6jIZuwBBh0uqS/ZxSA0kHAVcLrdG7kLIVbJpQ44iH7nXTahm/ORu1531corjuVNyygylEpX2yD0Zq7NllGefYxBryVbui/LcDA55LJ1sc1vmS1+SSzW8sGoJjEQVPUGoch8YCCh3h9ylci+X5Z/Pc7ctj1xO/tDp2lhkIEqjOy4n9TSW2886IfdkHFIpl9xjhfBJqxbQVq3epSW4917n6ZHDckGSSgJWh0yGERacTQGKZZ20XvEk+Ouo2S3jpCL3eBziVOrJ/emn2Tu/kXis5pST6wRdK3ePYd9UudtFiYNJrRzPveqvn6qgx2uuclfJlmIhJJHNyitLrSbJXdfrLhQAL7YXqT7F80IHQWnRLptmR3t0mgxJLfBJDepu5GWLy+/LZaiKOBlDfrfvwhmYUC1qGb8tk5FDIFS5e8k9XqFUDY95dc5Jxj1XRioWotzd4TZ3VL6uyN1LEkbWroXbgNxnZ+sDS5wC4wFFqtqXzUaRe8zpRsViwJYJkPtMbTRSuTt3HA2Uu57ArSeYy7Ftm7Tb80V/crK67ZXnnor7lHtWKwYKKrSOtorCfP7zMnm9/UOOHNGY5AhaOoIAbOUOHhu3miClVz1pQjpqdss4qcgdIBkr13uV//mfPMQuTttWbp2MQxAMV2+b3EsluP9+eO97Sf/aO4AGyt3O/WwGfF5HJZbtcM/ghGqiRlnY26hkS2HKXY3eQsG/gCkAJ6qHZKg3WVywyV3lqO5wYUbJJvfkoNFszVQdnFzuSUlEDSdUtVS4cveEXaqPJzFdctcrFCvBWWkJ524q4yp7x3P3Tqh6zuXcMfn60oI8XgPD7nuqFm675G4JeZem6/4yheo4KnWu4JJ73Dlm+XyA3DOyfY5yr4xGKne9QcIzR7nrwvV8bOUO8Cx2kroo5e7x3EkmnUVzA1ru+JD73Jz8YfZd7pFjktwjCSCE3ItVg7RRBV3vk3snSMYq9eR+++3sjZ/NzheGD85WMToqBW7HtgzAi14En/scqaP7nH2EoSm5VzzLCD3QE57ViUq5xyNsGfCTewjUZGJd4QnVTntuQIWndarcVTUkn3Jv8bbVKbFnj/GGtgx+cleTcd4+E6bc03qFUk0PXSvvnJOsh9xDiMNr68wek8dpeRnSFEhk3RVQTrnEiGOpbrbqyL2m2+QebstkswHP3RM77r3W+zx3+/V8HkTJZKY8HK3c1UU5xJbxFWpPJOTA8ZD7fux/oshdpa42NL9yp34hX6twjlMrHc1ZXiznp45MxyW5hxWFAMhmHVtGLWQqVg1ShoBYrO+5d4JkooIZCB8s3XYXT1a3s3Nn5347yFB1b2r2tsj9vPPgrLPgD/4AfvQjJ51spHLPyYEdTEfrqMSyTe5BWyYh3LwirSj3fL4hufuUewNyVxOCHU+oKoLsRrmnJak0tGVE2if0lHJXWSkhwpbRZY3XsFVnqr8Fyb1KgqrpVe4eW2ZWtnV5GalCvSSRTMrUzRF3QQsLkuDzgeUcptBJ6qLuwhLpudvnSk/FfRdEn3K3ST6Xg8WiQUUkoj33BkVGnAlVlVzNrrHXMrmrC5GOf0JVdKHcQyKaIqH6kFLus3rbyr0kkqST9u/Q/DmgVgJdLWLSNO3/A34VEMCDwH8FNgL/BIwB9wL/RQixwlMHLgxd+G6xOXSIx55NUSPOzp3d739yskPlftppsHev/D+XkzHZNFDuNrkHfV7H37XsdevBCVXds/TcUe4hE5NB5e6tQ+aBEwZIKtxzV9VlxmQ7yx0uzCiZGho19FQcXQW3hJS/C0OQ3BvaMiTZ4LVlsvVhh+HkXpPHwDTr4gCtYpUYgnjGJWgv0SnqMb3K3Q5QWs5pDcg9/FiqbdWUScy+ZlhCx9BNdCOBIEa1VCZOA8/d8bFdz31hwb/w2SH3ZcFMQX4oMlpG3XGFnDfHllE/c3AQcjk2bYJEvMb+qk3uUaGQ3qIzXnKvLR1fcp+dpVKBmUVF7rvDP5/N+shdpelIp+xjrvlzQK0EOlbumqZtBn4bOEcIsQuIA78C/Dnwl0KI04B54N29aGirSOpCFqtQXueDD7IXyeq7dkVv1yo6JncvsllS8YqzjzAU7MT+Zs1P7o7CVeRep9zlIAdc5a53rtx9tkyY525fhIbHFbl36LnbS7M1zXN736KycWyZrOzOkbaMaVISSb8tM9CE3O2lyinDJveQY2AWKr4Se+AeN6/6LlV1huJyrmRuXv625bxN7v6VVRhYfpHiQVhmUqpVLAwM3a1Bq0Ipm9sycac7qKAVh9wH7SLZCxWmi5Lpmyn3sCgn15axz+nAACwvE4/DKUPLTZW7z9bx2jLVpc6jZULy/0TCY8tMT8uY/Ya2zMSEz5ZxIrDsdRWGVmm5f3eKbm2ZBJDWNC0BZIDDwGuAm+z3/xG4rMvvaAvJpE1EKrxv714eYheJhOD007vff0/IXdNID0kyjLRl8vYiphBy1zRIFG1yD6gWXfcUqlbKPRFCEl5yV7ncQ6DUWKQto0qHTchO3umEqmnFSNopFRopwDA4yj1r1xCNsmUsi1LN8POoXZpR5bYBz0BMuVeaVNKj3INtL1TryD3MojCrCSZSyyQoMzsvh95yPi6JyksSqZRU7hF3QUq5e3875TImSZK6cCY21SIlddrqlbtN7umEw4/HZOlP13Mflhe//GKFGTubZTPP3QpJ0+Aqd/uc2rYMwLaB2ZY9d8PAP6FaW+xCucekdVZqT7mr8d/QltmwwbkALS7WzwvpsYovB9RKoOO9CyEOAp8EnkWS+iLShlkQQigZdADYHLa9pmnv0TTtHk3T7pn2ZuPqEsmUnbBJjYC9e9mbfBE7dmj1S/A7wOSkHADVahfkDqTsupyRtoxd9adG3Fdj2TRlB9eKBdlTYv5TqDzNsn33Ij33BrbM/Lwk+Ahy1zQPsYXZMvYdxuAGub+O87lbMadmqZOnrMUFmg65D7qpFmIxj3K3LCcbWLGW9HFBPJOU4bOeyBRHuQ+7hJsyhMwoGUI+VrEWTe4egjZrsl7pOuaYW5KkuVSIh9oyScy2yd1CzlfogULVXuVeqbhzwupceT33oHLPDsljmltwyT1KuavEjGEXZUd52wU9fOSePNL6hGrQlqE7zx1aTJnh8dxbInfDQB8bJpMwWVz01ysAmQPKmyZkJdCNLTMKvAnYDmwCssAlrW4vhPiiEOIcIcQ5E1FSoAMk0zFJ7ure9aGH2Bt7QU/8dpDkXqvJ3XdD7ulRuWF0bhn3xHsvAJYVUYXJhi/SRCl3vYFyP3BAPkaQO8i0uJHKPV9Do0Z2vV2AoFNyL8dIxeTAjsXkeoUwBRgGRxUNSsK0qwj6qzGVStKWCSh3UilSlCh5il87oZDD7gdTSRFtyxRrcnFOMtxzB6BWoyQMknqNMWaZW5ZtXS4moj33iJkqry3jTKpallTuSeEWOynWkzu4jmUj5a4+q2cNkpTILVaZLsv5h6jhqmlgaFboRdmZUPUqd7sqyLbYcxxiE2USrZF7IsGQJrftJlrGWSzXSoSXx5ZR5L6Bo9G2DMDGjYwkciwsQHFebq+sQz1WpbxWlTtwIfCMEGJaCFEGvg68HBixbRqAU4CDUTtYCSQzcVe5C0Fh7zM8XdzYM3JXse6HDskO1ym5q8Iikco9JEuh+t/J5R6y6MhRbV7lHkbuakAocg+r8qvaajTw3AuiJzmqzXKMpOZePIJ56RuhsGzHtw+5E5ZONSYvuVsWpapeR+5JTF+ElaPcB3XP/kS0LdNIuatDZtsmqaRgHXPMLssPLBf1SM89itxDlbtl2Z67TAQGUC7Ve+7e517lHuW5k0oxQI58rsZMZYRUotyQSw2tHGo31NkytucOsK3yFDXiHOCU1sgdGDLkSepGuau7iJYStLVrywBMTjKMLNihFvup0FsjVnUytq4Uutn7s8B5mqZlNE3TgNcCDwO3Ab9sf+ZdwDe6a2J7SGYTLrk/+yyH84MIYkxN9Wb/Klx9/3752Cm5x0aHMTQrmtxN99SEknuEcveRiuO5h3yBGr3PPScfGyj3VKqBci/KIhmxdSPEqbScMiCIUjlOKu6yWTueZGFBbpcZdsnYUe6eUntVs4JV0/1cYCv30EVMA7r3Y9HkXhLNyd1R1khbJi8V37Kpt63cw8i9WipTJYGR1Fy7oeSva5tJmL7nDrk3UO6k02TJk1sSTNfWMZHJN6xfoGvhd1yOLWNn/PTZMqXHADscMuJHB2sB94Lcm5UF9EF1irk5Dh+G4VSJNE1u3TduZLg2Lz13e7FfekD+fj1e9SX4Wwl047n/CDlx+lNkGGQM+CLw+8D7NU17EhkO+Xc9aGfLSA7qri2zdy9LSEUZlp+9Eyhy37dPPna84nV0lDTFaFvGQ+7BXOOh9VNtOMrdEq5yD5trCCr3RrZMskEopF06jOFhmS+jxZQBQcgqQp5Sc1ql5dtWld8mPeISZFiRbHei1LOxrdxLRT+561rZF9qYSmmRtoxlCmnLhJG78p/tEn9JXTAWX2S2kJax6pYRTe4R83xeW0aRuypvmEzaybVwScuyZFoK408+DHjIveySu+JHpdzVhKpS7rmlGjOMM55tUD4MMGLhd1yOck8HyF0Iti0/BMD++PNaVu7Dhhw4gyx3bss0qRzlQ0C5O+X1Gtkyk5OMlKdZWBCucrejs2Sd25VV7l3FuQsh/hj448DLTwMv6Wa/3SCZiWNqKSlvPOQ+1HmmXx96Ru4jI6REkVJxCKgfDN6qP97+7vPcQ2wZV7VVbeU+EF4GUA2IFpS7E4EUptxLMRmznx7rakl1qZKoV+4t3rYW7Dw8mVF3oIXZMqpMXqgtY7pDoVRCTu56SCOV1qKVu0nLyj2VrLFOX2KumHYKUQ/F8v6JcYfcw3//7KwUK4uLrueuwh6NpObWoPVMqBrxCnpp2demslLTGZ1YTDa/Trkrcl8eZ4EJJgabk7sVkho5dEK1VoPlZbYsy/Uf++Ongjlbty1QV+h9Z3Yfn459jDdM/xuk39WwTZFtTXVuy0xmluUMcljuY4XJSYbFPE/P15zFfipKTo/XKJtrVLmvVSSTGmYs7ZL7uu1A78h9YEB2/J4p91x4xypaCZL2KlavZdDMlnF8xHy5sXKPxSQDHrSnRBqRu4pACvPcTY10zOo6GZIkd1e56214koXlCjGqGMPu7XmYLaMKXIdOqJbcC6xpx9wHyd0iSa0UMqHagNxVml/HljFgTF+mUEk6RDqoBwjTMGSce0Qo6MyMu+bMqdilCoyntDq7QZJ71aneVafcbaskm3XvCuo89zxSuQ81vjXTY9XQi7Izoary76hbg337SGEyOZRnvzYVrdwD5K6lkvy29hkGyXWu3DNtKHffhKpgY3qh+eDfuJFhFlmcF85iP6XcfdlbVwgnIbkjlfvMDDz0EMubZBpIlYiuF5ichGeekf93pdwpUQpmsLRRKCcYRdY2NXP+IsstTagWyp5omYg2ZDIydCIeb3j1cyyJMFvGjJGOywLF3eTLMKsJkgmPLRNr3ZMsLldJU0QbcI9HnS2Ty1EUUtn7LFo77ND0nIZSySZ3zwed7JG5+lAQy6ond2cRk7KWTNP13JNSbqt5mzpy1zQMLXrOYXYWttp5toK2jJHU6srdWZb0wnX8icQc5W73j0xGimkI8dzzMaaZYGK48WJzIx5+UQ61ZQCelkXrt20osV9sjV7EVAmUi0wm3dq/nXru7dQNKBblOLEsDh+GydR8Y0sGpC3DAgtLGkWb3NPD8qqvJ2pumpAVwklH7oaK7JiehkceYWn9aUDvlDtIcu+Fck9RCiULgGJFd1a4lZbcAeV47lETqiq8q1iBSkVGUET1QTWCR0cbVvlOprVoW8aKk4rL13UqLcemB1Gq6rKQgY1g0ZFGKOSqThUmBceWUQN/aUleoIiyZfyhp0kRsGUydlGP5fpjYFpac89dJS1LCsZSAXI36gnNiFdDyV2ICHK3rQUjFXMIVJF7uSztkjpyD/jY3u7k/G8r97mczhLDjA83PsFGvIpVrbcqnJS9NqHWkfvmKvtrW5oqd+cuNOnpj51GyzSp+eqgVpPt2riRHFlyOY1Jfa5l5W6W4yzO2ymt7bUTetxfxHwlcNKRe1ItKX7gASgUWBqViyN6Te4qAX83yr2hLVM1HHL3KnfHc4+aUFW2TKEC5TJldHfJdxBq+waWDNhWVxS5l+OkEza5R0RKtAJJ7u6xMOLVlm9bC3khyd2ZBQxR7ouLkeSewvXjwVbuwn/xTNshbKocoBdmWYv23IPKPaWxLiOVukPuyXo1nIyHK/flZXka6mwZVWA8HaurQWtZcoJakbvjuds8rchdXRszGc8UgE3uB5bkAJoYbYXc68+bIlDHllHkbt8Cb9se49nqplDbC3AmaX3KXaHbCdVmyl1dcDZv5igyFnqjMdN88E9OOvllVL1XpdxlDqi+cm8LyaS9ZN/u9UsDm4jFOj7/oVCTqtAD5R5CFkJIcm9oy0RMqDpqxKfcI8hdbd+U3G2rK8xzV9VlsJMhdajc/297bx4lSVafh3439sisvau7epvuaZgZmmEfDWgwiCdgNBbrjDgYED7vgR4CH0u2R8h6fsiypYd1EM/n+Rlhy0dHo0F4pINATxixyoIxg2UjaUCDQAiYYRiWgR66q7eqrqrMjCUj7vvjLnEjY8nIzIju6ur4zulTXVmZGTe2L7773d/ix6zRhICpVZ+2Dvo0o9zzyH3AS3jl2jKKv+0N4qwtI8g9Z6bFSicUkHs44rk7kOQuZn/zTvahWUSSIgzy0P4hdJ1mF1QdLdeWsUiY47mzsYk1QXGPpC4rx0EXPcSUUcXqSrnKZVEgOQuqfS4AeK16+SDm5H7wuI2AWtju55/zMNKgIUoeOiq5T23LVCR3sZh65AhO4xAbr3ZuvC2zuIglg52gM+fZQRaZ6aZOkxpQDWFPknsYG6znJ4BtZz8WFkpdh4khEpmAqa+rRLn3s38KAoBCy1XujNzpWFsmpdyt2cidxXi7+Z57ZCTkrk1fDMmLbdalhqNoep+Hfp+wiJ1pbBldh0MC+ErHK68XZxdUS5R7MCyxZYT6lrXkCfbNMSUoyF30n1VhGeXkvvqH/wEdMkiUuyg73NEzjaqZ5x5mbZkhYCCU90YuubsuiyXnWN1XToRsoTDHluEzi4xy57aMu49tXA1JVRFGWrqjmHoSZ2jWAUxA7keP4gyYsjuonR2v7AjB4go7h+sbbGMiM900kVRvbQh7ktwBbs1cdx22fLvWxVSgZuWeYzGKa0l67krFQt9nNxDiuFy5e4pyd2a1ZQCfFNgyQwsOrzo5SWz6KHxqwrES4jT16tPW/oBUUu655A5mgajtDL1+DrnzKIdcW2aoM+WuhCWNkvuwHyCGDtvVsDLPjqNU7p2sNWcZce7DTUSz7PvOX6ODfuK584gPy9Gkry2SlIKA9S4dtWWCUINJkmtL7K7ibklbRmBcpRDLiHLJXWTLml1+YFRbZmVFPjyL8j6CoQ5LyYOoxZYpqT+fgoiUOXIkIXeyXunmF9VSz2yy99pLXLmbtCX3SZEqUfu0p2Frq16/HaiJ3BcXObnnxLgLcueJGr5SsTAIGBkByPfcpS0TgQYhhjBlOnoGggxLSg8AY+LcYytpQDBDMSSP2rCV0sSWka8A8zDw88nd94HIrEDuxhC+opJ9kZil2jLjyF0fpqaHkjh45IgMVXQ1dOcILBLIKNR5N2v1sP0vVu771r+BLnpZcu8YmUbVYQhYNMjaMkOSIndZLEzVDIaBOZJ0BVndX35+TYMiyCGtYBBBxxBahx98Qe6eB+zfn1Ty9PK/P4xHlLu40TUNxeFg5ahM7ootcwYHoWsxVqOK5H6Q7diZLRc2PLn/lgmEsPIae9WGltynQC3kbppwjSEGOYkM4lpa7jBZLxbLAG7LaEpTzBFIH3EQJYtYdSh3mh/n7o2Qe14CyzgMh6xrkWMnV7ppxJWVTd/XWay9nmxbhrcT/p8izx2AYwxTLfBk1q2q3OeLSzQHkQ5bT6vvRLmnvXrbJSCugxVtE1HECqSJSoGpzxs0U+4ZUGwZ/xQ6tCc998SWSZS7VOgBYMHPsWVIrnJPkTsh6JrsAwQxVlbLKcMy4twokNCL0sXV1OmBQu55YgfIsWXE97ju1J6rrD46rmSGOOkLCzhtHMOauw3NH4z33AEsHWYH9czOHLumtHRI53DKNaoqaMl9CtRC7uCVBnPIUCr3ed5qr4jc82wZMSX3Y5mhaNljlHslzz2r3CkFBjTpSWoWxDiPg2xAYiU3GVOu1RRZPzDQMdIPHtmwI66i3ONUO0PP43HrebZMjifsR0amIYpMYuLfK86h09EB18U+sH4D83ofxM1eRJZJMaSGjDsXOH8eIIRiCZvoxDtZ5e4aMmIqZcvQHHKPKpA7gDmLHdtlbKR6vebBMvIXCgMvZtuXF4uZ3Kyrq0mViEJy1/PJfYZIicRzH/NGYcu4Ls6YR3HQ3uCZbhWU+zFW96QX2nBJks+QPFgmHXV17F1y/5f/Bnjd67C9XT+5HziQ/H8WcnddFs8+Cknui+yGVa0A32dlVQGUKvfQi5LYYmc2cmfK3QIdKXYShqzevMvb202SVapCVmFMKffqnuQgNNAx02OT5O5p7C4uWlAF4JhRmtx9krFlXBHnPpJvNBwCMdVgG/nkLm0ZEarY0QHHwQqYBJ8nvVwFmKrLr+DCBWC5G0BHjA7tJR27eBaz1U0yksVngwAw48SWSUIhNZgkIcxCcrfZF+3H+AgR06QIkG0kHoiyyOrBF9aMassUpOQHsVGs3KdEJqKpCOKGdBycwSEcMs5Wrvc9f2wZBOwcOVoiQMqaideFvUvub/wZoNvF1la92aliG4IPZ1LuLoEXmRnfrc+7MC0tc2JQyg+wbMiRGq4KRKhZ4FVQ7hPYMhQahkGawEa7y1h6NFUxpDxytwzK6ntXMCX7oQnXStsimW5MJbaMbcYYUkP2vpbkrip3WaImPR456xhR7oYBaCRZFBWdnuyuAbguVmJG7gtkO5cwxSxm1Am7cAFYdZkX00UP/W0e7sgf5HZHz3SyCkPAir0c5a7B1LKee2pBFQm5r+L8WHK3TIoQZsZvCP1ycpfHN8i/fsJYh6VfIXJXlPvp6AAO0jN8ejfeltEOH5SNRVy1dpKVrrnfBPYuufObrglbBmDWjKaV1w0aB7ergULLqDNR5bC7bMJEIP3UKGL/bPCdy1tQVWyZTJnVUUxgywBZ1SqyNYWqLYpxHgepapW1AaYALUjGLUE/stGx0+/LNMlWbJnRe9LmUTrimvECrYTc00Qga6bk1O+xtKFcFBXn0Oky5b6PsvKLmYqQ4rMFi33nzwP7dJYY00FfKndB7kXKvYjc1QiUIuXeddixraLcLZNHqo0MPAgo2776+TzlHhbEucc6TF15gNZpy1RU7pHl4my4hIPRE5VtGZGlCkBmcgMjZUIawp4jd+l1+rLoXCPkvrbGzu0s8fPOXH74lyxhu9JhCTZcLUqVSDnL5tkyHcVz95PwuFxMoNzV7ctx8u4yTkfUqM4P3xsHWVRJuVekAhxjSkYR4McWOk4JubuuJHfDoJkHsmOlj68kdzVaRpD7iCect14g90GJ1ZcLnkK5C88dW7kkUUTuFy5APhg66CcLqmIcc2ZGuQcBYEWDbIbqyCJloS3TYWOvotzlQ3nkvIU5ZZHlFEFdUA0mJPc6lPu43Ax+g14YdBBRHYf871Zvw6ZkqYpMbgAw7ZbcJ4aMcw+QlFRtSLnPYskAgMObQYwq4oTcXVZrnP9d3MAW5f8ps2V8qnjuBWr6jjuAt7wF4zqZSHIP0jeBbEAgWofpdCrlnkfupoFKnenljHnkXGRsGe65q7H0Aja3gzwv8dALlftE5J6Ec6bI3XGwT3ju8Va+crcTYlZx4QKwGpwGbJspd96OUVXuo4t1QQCYkZcNhYw0mFpyPHJDIZGQeyXlbpHch3Lg0/SCKpAod3VBdZgvDkI6Qu7iAzWQ+9jEO36Rnd5iB+Zg/7tMNVSwZbC2JvNV1NpJ1mVQ7s1G0V8BqCqTN3pphNxf/3rg6NHZvkPUdh7sRMBaQoqDbXYRuPtZ+JQgEHGj25RL/TxbhpN7GCjKvaj8wFOeAtx779hxJuSefl00IBDdZSxjunoZarlaActCJeUum2O7aXLN2DKUNbh2nSwJq9eM9P8LyH0woiwluefc55YRsZhvSpPvnRtR7vGlicj9/HlgX/x94KlPRecrffQHfF2GP3gtV5c9aAVpBQGFRXNsmViHqWeV+6jnvtQNsYBLuAmPViB3rtwO/9ZUAAAgAElEQVSDrdTrQQgeCqk8OXJtmfwIqYCasIx6bRldZ+GdY+shceV+5hIb5EE6QY9N08SiOQBCwFUysFM1oBrCniZ3Udyr7gVVALjzTvZvFogKcd65beDJS/J1Wdh//1yqHK0kkoiTe16zjjkmRwJfaZAwYwmLRLWmbwKh3GV3GWNK5T7SGR5gYw5gAcOClEUOSe4j93jGlgF4+n/2Oxx+zXjeCLkrqtAwAA0RvKDAc88jdz2W6wZSubsaj5Zh5L5A8+uC55H7YMD+7cMPgac/Hd2v9ND3dVCqPPj5OFgRN9GVK52hmpC7BlOZyRTZMm5Xw3dxAotkGzD+c3ZHFZgWq3tPgzDVgiYMUKzcVVuG8nUWPX0dhbFRuy0DoLS0soQgd15C4CB4E9WKU/fFTghcQmrRX4arDpoj9z1ry6jk3oRyrwOiLZx3bjv1uqgU6S7zcrScUCS5xwWMBkB3LRDECAMqw6xym3VMgEJbRjyE5hNyn6YYUipMkKOqcpcRO3PpSzljy6CY3MWMQVXutppwA7a24mp+xhNOlHteIlIkraWUwnfdxJYpWlC10+ccUBKYcB54+tNZVi7fxyBkKlRwokXCtHJHTihkrKdsmSJyZzONDejO+HMr7IZoMLKgKpR7gecuZ0Zws9MVyiKnTEOZddWg3AHA0vIbeqfgeQAhOHOe7b8k9yq2DIClBZ7joJbXaMl9clxN5O6sMAYanO+lXpfkvmjB1kKpmKXnPhywUJ3cEA3REYnWptzlMR2ZvmZah01ZL0OECYqGGABgWiyGPvKq2TKiJK+AuOd7PUimH8DNFXpixpCyZaw4s1ruaEGqBo34DJC2lAQsgyv34VDWEHIcpJR7IbnnNG+WdWVwAXja0yS59/tJZUoxZFNRpEFICpR72sc+epRdVsePjx4gzrwVVIKccYzYDSEfQ2pfb7sNePGLAcdhl7M+ZOQ+unIfRawAnp5D7rMqd204vinMYAA4Dk6fIZjvDNHlx72ycl9kx0RkcgNqJvkuJXdCyBIh5MOEkEcIIQ8TQp5PCFkhhNxPCPkW/7lc12Cr4HJ57nXAWeaV8C6MkHsvhoEQxkIHjhZIUpVT7yHvwpQXqsNbtAW+0v2mJuU+SmxeprvMdJXu8sjdEouCYy5+0T+1O5++lMU539pCWrnnpPrbLu+ypNoydtabd/QwcwykLeNmbyXLiGVNHl/MCLhyX8M6ADCSz4tzd4UnmzzcZF0ZXEgp936fEzhRojEISyijlBGriRAs8DZSyN2AqfjYT3oScOYM8Pznj+64owy+HDJ+e4TcAz6G1He88Y3AAw/IX10ryu9TKzqK5Sn3mck9vy1gCpzcz5wBDh7IWdQdg8V9vNyvst6TKPfdG+f+XgB/Rik9CeBZAB4G8A4An6WU3gjgs/z3y4bL5bnXAXeVzX8HF9O+cr8X86bTLmxtKMldqsRhfqMOAICuy16mdXvuGVuGzzDE2oEMX5wQ/iBryxSRxCj6FxlrdhbSDxXbZrP+8+cxQu7ZS14Qqe/R8eQ+Es0hz0ne9yphgeLY2TYbz0Gs40//2Z/hjfjDfM9dKLteltxXrW3g2DF0eDp7v89mVSq5W1qIMCLJA55bMiYZJrYM1dNqGAVVHycgd9mgfeShHAxZ68BUI/DRzZhRvnIXvYDNBmwZfTg+q9pj6y9nzgCHDin3QFVb5gAv96tGg6l9FxrC1OROCFkE8CIA7wMASmlAKd0EcCeA+/jb7gNw16yDnARXlS2zyjxHbyNN7oM+i2FGpwNbH8Ln9WckkQTbuYupAABCJLnXrdz9kTo4qn0EsIdIhGw9lHHwekqCD0cRSYyid5EdlO5SdsawusoJUbVlcrhAbNfvR/IY5yl8Rw/hRUXknp3aW6Ziy/DMS6HcAeBl130NcygoPyDJPdl/acscdQFNQ7fDyK7fZ+Rpq8qdF3FLkbtpMi9eKHeaVu6FEOq4Crmr/QQUhEOSiszJ3YwV55O76EvQgHI3tbi6LXMaOHhUT2bMVZX7ITZG9ZpSy4Q0hVmU+wkA5wC8nxDyZULIvYSQLoA1Sulp/p4zANbyPkwIeRsh5CFCyEPnzp2bYRhpXFXK/QAbmAgpFBgMqFTurGJhmtytsES5gy2mBSGR0RK1ee4j5C7sFLUBATB5MSRRO0dE3QBJkse49Ow+zwnoLGafYPv2jSh34sLJ8calLbMdJso9L6rGGGZqAYkEM3XWIWCllLvyveLLNzf5AErIXSFJodxXTrBiVOq6QhBqsDRVuTNbRtpGCIDlZdYtK2XLVKhtMoktI0L8Rs5bMBwpH5AD147zbRmu3M085T6rLVOlKYyi3A8e0oAlHtlWldyPsPtcZHIDiXJX11TqxizkbgC4BcBvU0qfA6CHEQuGUkoB5F49lNJ7KKW3Ukpv3T+uA8AEUDNUt3jy36zKtSk4K+zuHIySu8c7C3U6rNb4MF3C1Q62S8mdtbsj9XvuI5bEgCtuly8My5TqCYshSYLsJt9vVYwm6G+ynewsZXdydTWP3LPfIbbr7yjknqfcjSG8KL0d2d6ukyUISe7DIXyu3C0LCSEJcs+zZUQ3pRFyXyBbsE4cYfushHv6Qz2pFgpexC1OyN1EyMgdinIfjUApwiS2jGjQPqJIw4iwJjNlm7ELlLsgd/UQizHNassUNBdJYTBA31rC1hZw6BCS/gcVyX3pOHsYO10lYKBqc+4ZMAu5nwJwilL6Bf77h8HIfp0QcggA+M+zsw1xMhgGs/XEguputWSAhEDEwqSAJHfX5eVoR2wZf6vYlgF4RyTUptyl5z5qy3A3SXaXERl/E2bdiTK6KrkXKcBR9C4x8uuuZIlHkvu4OHelP6oMhcxR4q4ZwYtGlDtvgThOuXuhBpOEzHJWukOxD+co905WuZ9fH2IfPS/DWTo8/LPfZ9Un1ToxJleko8rdooHiuTdH7hnlHuljLSDXofmhkHxB1bIaUu4VyH1dPwyAl/sW5F7Rc198xjEAgPvcZ8jXZA2o3WjLUErPAPgBIeQp/KWXAvgGgI8DeBN/7U0APjbTCKeAbSfKfbdaMoASi72dVqcDT4MLDzBN2GYs1WKK3MuUu8bC4EScc22e+4g3OehT1l3GtVPbmZTcfY/CRADdVdrUCc99zMXf58eusy97k48q96JQSJuXgfD7Cbk73SxZO2YEL04fTJld281T7kkJBT/Uk5Kvo8o9l9zFmJL9v/CExyJlBLkvsDEy5W7AUurEiAqdGVsGAVPulGbVcBEm8Nyl3ZAhdyOdYZoDx8YYW0aZTR07Btx0E/DMZ44ffwkqdfzyPJwmOeReUblff4LgJ34CuO32JPVXzswatGVmzVD9pwA+QAixAHwHwM+APTD+P0LIWwA8DuB1M25jYti8aVBTFSHrgsz87KVvhEGgoav7ACGs1rioTyI8d28L6BS3xjO1COGwAc99xJv0PLAZBuGeO2/nN7FyF80xlKeQmRPnnYf+dgQNEayl7MNudZXN3gKzCwuslV+ucudev9+LEnLvZHWPY0XwaJrgpC3TzR5kyxJZtv20bVLFcxc3v2JLXViPGLnzWkBdHiEklLtsvwixUGikF1SXl2FSTu4idtysWbkXLBSGsTZ2luC6FJtwAf98+g+S3JXXlpaAb35z7HjGjrdKyYzBAGdMtnR48CAmrvftusBnPpN+LSkT0lw995nInVL6FQC35vzppbN876xQlftuJnfTBHQSYdBLn+BBoGOVlwe1rRg+V4vSc+9dBBZOFH6vpQ1ZpERNyl0+hKidSg0f+AQOSabQMnyxNxm5DzxeP10hD8upFk3Q26HoogcyP5f52+oq+3khWsIhFJO7Pc8OkNeLYKk1YEbgWDG8OE1wMrs2T7lbinIfKuQr9rPEcxeziWCQPNw2NymejA3g+M0AgM4ie0+vx2wPy1CUuxGhT/UR5X4YFvURBDSJQKny4J+C3IMRLzmIjXQoYw5cl5RHy8woUvJgGTF64zp+DQY4o7MOPSnPvaItkwe1NHdT2HMZqkBC7rvdcwd4eN1I67ZBaMjyoLYF+DylX9oyOxdK/SZTixFGRGYoznpTyEXqkVZ7A0+DqyU3olnRShnF5o7OKuepyt2uqNx7NNMcW0Dcg+fDRUTQEMLKtWVEPR5/ECehkPPZg+ZYMWs3qDQQkeQ+n32CWhY/ZsMhvKGZ1PMmhBFmmXLviqYrybG8tGNgkWwBh5lFIBaR+33Aj8wUuYva+rkLqn48GWFOEgopMy/T5y2kBqwxyt1xSa4tEwdDRDCkeKgTppHfOSoFz8OZ4So0jQuGCW2ZPCRNzFtynwhXi3IHWI3n0e4+g6EJ1xTkTjGEyeqWC3LvXSjdMdbLVJfJGbMqd0JYsscouXuBlu4uY09ny2zsmFjGRmqgcno/ZtraFzkBo6UMkSj388FCYYs9ANA6Diz48PpxunrjCBybL/gpx8AfMFsor7eobSvKfbSJtutWJPdk/zc9G0vzsewQYy260BAxWyZOf7+pUwSxmVbuS0uS3GkQIoRVu3KXnrufjJtSIKSmXHAvgtvJV+4iYqqJqDfLSCKaCjEYYD1cweoqn7TeeCNb81paKv7MGJjdpMBfU9jz5L6bF1QBnpXnaynl0B9asjyoSFn2fcVzR1BK7ix2V69NuQOAbfDUcFW5B3qK3KuGL45io2dllXvFOOBeX0MXvdyoCUnu/nwpucPhBdoGMbwBBUEMcy5LZI5FM8oytzcoh2UThdwN2Eo9bzhO0nAg57PGHHtN7L/nAUFsYnEl8YfJwjxrtbfDIj7UBUvhJUvP3QTQ6XByp7JmT2qRsgiT2DKdrN1QNSTX7Wq5yl3MBJtQ7kmJ4qD4TYMB1v0lrImMnde9Dvj+92ciF7U0d1PY8+S+25U783GtVDumQWShY/EoDKU6YBAAhFAYGJbbMnrMIiUiHTqJyjK+q4/TjLK2TKinGhBI5T6pLdO3plfunoaO5uXW2ZHkPuhWI3ePwtsJWQGubnaB1nUZuVOlsL3vxWwxuIzchyw+Xj1WqYdRDmkSx4YFXypgIfKXVpT9nJ9n3Zg2Q/ixBVu1ZXiFzqQkMbOCWN2hWD6Ax6lpAFORu6rcxSUz7kHiCOU+QrTiQdEIuRd0jkrB87DuLSbkrmmJNTMlhHIPS54ps2LPkvv2NiPE3U7uMrZ3YwMAE/CDyJIV5NRytL7PbBoCjLFlWF31MCKp2OdZYJu8CJZy43lDA66pkLuTjc2ugo2+nSH3ZHo/xnP3dXT0/DtE3H8XBp3C5tgAAMeBAw+eR+HtRJla7snbCOt5u5MoS39AS8g9qWzpx0a6ibb6/jzStG1OxIwkRUj84pJCcHNzrBvT1hABNWAp328arEKn9NxtVkfeRMjKQfcnUO6yA/r4J4HsBKY8lMtq3qc209Xhw0E8yLdlzKKmMzNADVfNxXAIDIc4O5jDgQP1bVd3zFQRtyawZ8ld1OHY7eTuODy2l0uzMGSEMEru3s6Qkbu4gctsGYMnsEQGTFJPkoQkd1W5D81ccp9EuVMKbAwcLGMz1aBBKne/XLn3fANdM9+4tCw2wTnfc8uVu21z5c4iZka7MAnIqCEl6SzI6w0qtq8sCvuxCVuN8x6j3AW5+0K5b7Cfqi0jlHt/O4ZPrdSCpWXGKXK3nBFyl8q9KVsmq9wLO4JxiI5eamw/kFhT4z4/Dcb26uUz6vXeXKLc6wAv8FfmBs2KPUnulgWIcjW73XN3OzxCgCt32XyCe+0Or0fhb/nwfSQp3GW2jEGZ3xppsPT6lHvGc4+s/O4yE5B7v89qnCwb6YYlIlQsGGfLhAY6ZrH8WV0Fzu/YY20ZBx78YAy552QU+36ZcuehoV7MwjCVYyXfbxiZrkMAEuXOb/5LZ9kDbGlVWUAR5L4TI6BmamYgetDK3qqc3MV3Sh+7CmFOEwqpkJacPVjldCMWsUVBOoHElqmfrkxrjHL3PPTQQS+w6iV3IFUKognsSXK3beAi64Ww+5V7R2eWAVfuktxF9Bm/WfxtdlPKRblS5U4RxgZL+dbqUe6ORbPKPbLg5DQgmITc+TMtQ+5JqNgYch8m6xN5WF0Fzm9ZY20ZGz48n8AfxMW2TC65o5jclQqJPrVgq3He48IL+WxCRFNc+iGr+b94QHn/PF9Q7TF/XY0jF4pU9tF19US5h4rVUYUwp6nnnmvLjFHuvPbKoJ8+58mDqH66sixSvqA6GOAsmB9TP7kPW3KfFLYNWXZ215P7nM5UJS/5lyV3Xmt8O2BEoo8nd7aYZiCMx1fiqwrbyvHcYwuuUvd8mnoZgtyXrHTDEqncx4SK9YY2OnaxL7+6Cpy/ZFZbUA0IPEHuecqdZ62q5SJ8n4wn950APmzYVo7nXkSYoukKv/k3T7MLY+mQ8tDhnnuvD/79yrkwWZtCYWmYrpEm90mU+8IC+3fkyNi3yhIUCmnJB4lTngkqba/+SIw8jyhphtzHK/d1Xti2Ts8dSKq3NoU91yAbSN8vu53c3SWbqcozrC+jJHeuYkRBKm+b9eGUKexl5M7b3QWxDtOoi9yRtWWoI+0jID/GeRxEFMjyYvozIs57nLLpRza6TvE+rq4CD3/NKCd3w2ALqoEGbUDHkrto6A0ovUFLWuX52wE8OLAtZXYint5FiTCEdVYKeJOPS+fYQ3XxsJKsxW2Z7Z6GCEZqvdPkUSCsxovJZkKumyX3qsr9298Glsc3VRNjSNkyOwEAQx6PIshaSxnl3iC520Queuc+egYDSe61K3devbUp7FnlLrDbyd2ZM+ERF/jhDwEoZXS51y4bSewwcrd4H8wyz90ygYCaXLnXE0fr2CO2DGVRPio3JSnVU9gyK+mLXGaoliw4xTEwoC46bvHDZHUVOL+hlZM7IbLjlaxzk2PLiAeuqiz9gCv3vFZ5/GEQbPvwYae7O1WwOiwSIuA3/+b5EBoizB1WLmhO7ps77EGokrtlAkOYssuV1TESzz3UJrc6ZAZPOUROhapIRWROXitCFamm5gpS6wY1Q0TwFEZ4NUnuWkvuE8NO25K7Gq4LeFoHOM36m/Q3GZuJyAFZa7zH2qPZhKvEkrA0k/utQWymGiDPAttOlx+ItvssnV9tQCASMyaodCfJfTVNHHnT+1EIEuh0isl93z5gZ4dgEyybsKhCrKOzyo2eqHOTp9yV0sACfqixc2Lk1JYRMxlhy9gTeO7gNYI4SV66GGMRl0BWFPXMyX2jzw5Wypbh3nd/h3vuHcWWiUhjPrY4DOp5Y8odMJ1yo0DaMl76dbHu0pRyB0qsRM+Tnnv9tkxL7hPjqlLuDitFK5U77ywkbRmF3NninTd2p0yTcHI3UvVGZoEkdy6le+ssu7K7oDS1rph4pEKS+8E0yVXp6tTnTei73eIbRCQyndKvB1Dsgtg663jl+RXIXQnVC0KSKrWrQkaOSHJXxikGUlKfxNIimWV86RJlWbyqNeI46JIBQl41VF2wFA/H3jZXvSq5D5sjd0LAkq/C5HtFITkrp+a9iiLlLqNlxnj200DOEIuK3XHlvjQ/rL38gSjN3RT2NLkTUtrTYlfAcXi1Ra7cRVcm0fBZFLDyeqy/p039sdMRywIoNHjUqlW5q5771mkevbGsNLUWCSwTeO4bF9l7Fw6myVQowLIFJ6FKO1XI/WVvBVBC7kYEf6jDC0hxtAwP1fMUT9gf6qlSuyoEufd3YkQw0tuuotz1IfyQfcfmJQ2LuAQsLiZvICQVKaSSu1DuvR2uertWYssMNYUwGwgvJMNcW2accpfk7qXPp1TuDZC7Na4pDCf3tX31N7I2tQhh1Cr3iSDul/n50mbruwKuy+K8oyfOMB97i11E7jy7EZJGEoLcB+OVu1BttDO2QUJVOG7alhHkvrCidE+aol7GxrkhFrEJff9K6nVCwBpLlExb+xeYxOvMF9/0ktwDNqcutGWMIfzIgB9qxcpdkrviuVcg922+jmq7Ocq9lNwjBLz426WejkW9l7mgO3ZCSupXCXLf2QF0DKF1nES5x3pC7nYDhDniJZe1IlQhbRk/fc6l557ThHxWWOP6BnBbZm21/howJu9z2xR2OfVNB3GR73ZLBlAvaACXLmGwxcjT5Q2fRSlZvx8hCAArqkDuPKW8h261NmoVYDskTe5nmTG6sD9hFLmgOkHW3ebZgJUeECysYFyoWO88I3fVGhqFJPdTfD+KwsrNGF5kwgv0YuXOZ1GDUeVeYH1Jct9h+2CrzbkrKXdWAA5g9XeW7H7mPepisrrgKFR8r8czaF0XsG2YCEEpkWWmG1HDJEzZDXJBNaehiQqp3P30+WxUuTtjGrFz5X7gQP1NNSw9QjCsf58E9jS57/bFVCC5oD04wA9/KGOo3QV2I0hy57XG7ag/3paxE3KvS7lLcueeuwzNU5JqkmJIE9gy54aM3HMKMY0LFetvCAurmDTE1546xZujFNxLthHBjwx4Qx2OFua+UVpkSv191iQj/xiL87DVZ9/lqNEiFTx3WyH3S76DRSf71Ox2km3nKffejkLuhMiHvVivaMTHVtYKgIQ4xcO/CJLcg/SYZOGxRsh9TPVRYcscbKCWvMYK/DWFPUnuYuHjalLuA7jA6dMy9dpdYneqs8h+egPKyH3YH6/cOan00anWI7MCbEdLe+4X2M+FtUThTkXuF+NCch9VgKOQ5L44nty3tsp7KYvqnIPQhGPmqzhJ7ko0hx+ZsAveL67D7T632FRyr6LcjThR7kEHS50suXeUfVJDDeUDfpuyRh18e9YouY8h3GlgacOU3VDWilCFnMWGBcq9ibGOyaoOdgJsYAVrhxp4COoxwqhV7hPharJlMsq9lyZ3e4H99D2u3MOdsTsmFol66KYqBc4Cp6Mhho6hx27UrQ02zoVDyYq1bunQEE2UdbexqRXaMuOUe2+DkV13uZg0TDNZgyxrnGNbFBQagtHqjQqEVZYi99hIlxVQIMnd47OwPOVeRu4ma94cx8BW1MXifHZcnTmF0BVlK6JAej0kyh1JFFJ/wPvrNqGGR6JAZIZqtzzcJFHuaRJvVrmXe+7nLrC/rx1pYNtGhDDexeROCNEJIV8mhHyS/36CEPIFQshjhJA/4s2zLyuuJnLPKPdeDB1DmAvsSte7DnQM4XuUee5hb6wtI27sPrr1KXdRBoG3T9vaZD9VcgchPANyAuW+bbAQvzzlPiZUrM8XnzvL5e3OxHOjjNzVBCPHyr/RxYNWJfey3qCC3Ld89p9U0+1xGargXYJiAzs7LPppaSGH3JXFZHXBVlwDO32SS+69AW/k0oAaNrUYgUJasqrjGOVuWQBBDC9ME16qsmXNGNcUZv0iG/OBQw0cJ52mjlPdqONo3Q3gYeX3fwvgPZTSGwBsAHhLDduYCFcjuXvuClPufQoXg9TNL8rR+j6FHfUq2DKKmqvS3b4CBLmLSBFRX3x+X/rZPWmluw3RqGNlJfM3k5RHE/QvsQ11VsoLWlUhdzXByCmoVUMMHTY8Gc0RRUAEI10zJvWd7OdWwDacaqJdSbkzcpflfpezx0Ild1W5CyLsD7QUuYsHTp+HGzZidehpW0ZYHqJXbREIYclkg2GBcm+iQXanvGSGIPe6s1MBwDRimaPQBGYid0LIUQCvAHAv/50AeAmAD/O33Afgrlm2MQ2uygXVfUeA06fR74GRuwjFE3VPfKUC4ThbRlE4dd0QosaNz3t6bu0QzJPtTKipSYYIK9oyngd4QxPLjpef4akNZShgHnrbjFS7q9mwRRWC3Ms8dzXByCniW0J4DZqkgQrA6u7kQdoyISd3NYmniuduUvjUwqV1NlVI1XLn6C4oyl35fqFIe76eVu4ic9VrTrlbeowgSr5XFi/LaV04CtcIMQjTF23II00bIXdZoK6A3DfZmJshd1aauynMqtx/E8C/ACCkyz4Am5RSEfh7CkBuKTlCyNsIIQ8RQh46J4qv14SrUbkPlg8z5e4hrdwJgY0AfU9DHJNK5K56k3Upd1njRtgyPR0LWi/zPouE8mYcB1k0bC5f6o+LA+5vM0XY2VfC2qjWrF79W6oGzOj7iC9D9SS5F7xf2jIRs64mVu4WqxG0eYplAy/tz7JbZynbmhBIFlR3fJMtqPLtySgaj723EVtGH7FlRNnhMcodYPkGXjRC7o0qd07uBbbM2W12bdVdegAQtlsDO8UxNbkTQl4J4Cyl9EvTfJ5Seg+l9FZK6a379++fdhi5uJrIXSr3pYPMcx+QtHIHYGsBtgbsxrAQVPbcgfr6TkrlLuqL900smNm4a5adWO2ykqUHFgtCCfVhSgGOot+jMBDCXJ4r3U4lW0aJQXfc4mPmEB9ekG5IYRUcY6ncwc6XSIICUM1zt5jtc/FUTi13js5y8pqaJCQe8P3QTNsyIpLK5+TeqZ9cLD29UCgTpubL10YArtyj9ENAzATrTv8HxvcNWN/uoEP6mCu/xKaCaIXYFGZR7i8A8GpCyPcAfAjMjnkvgCVCiBjxUQBPzDTCKXA1kbtU7gtrTLn7BB30UzLFJiG2PJ7UVMWWURWcVV8SE5DEeG95FhatQeZ9k5QxlbXcV/Ivw3FxwL0e0EVvbI2JSraMW5HctQBeMKLcnWrkPqlyF4XAzp1iT5Glw1n7SSX3PFuGIu25y8V2Qe5NNJ02WJSPQMCtvEq2jBllyF0sqjeq3EWU6aOPAp//vPz7em8Oa+bF+jcMUeBvF5I7pfSXKaVHKaXXA3gDgAcopf8QwOcAvJa/7U0APjbzKCfE1eS5HzrEMsr/zrsRGAww6FG4Wjqe2dEDGXFRyZZRptqVGiBXgOAi0dNzy3ewYGfjrieplyGV+778y5BlaJYo9wHQwWBsKdpK0TJKmKJdUprW1XwZzTGO3HUd0BBhC+x8iYQ09kUVPHeuss+dZj5XqpY7R2cl2SlVuace8HnkzsMNGyFMI07ZDWFAYSIAqRC65VgRPGqx5rri8yE7jk2UEpHRMqTaG5AAAB4+SURBVEK5/+IvAj/90/LvZ715rFkb9W8YgGlg1yr3IvyfAH6REPIYmAf/vga2UYqbbgJuvx14/vMv95Ynx/Iy8KIXAR/95kkAwKAXwdXTpGlrQ2z5fFEO4wuHpTz3mqaygoMEoW2FDhbcrFdukghhxUp3RRUh5XfpcWkccH9A0NGys4dRVLJlFEJPhSyOwNFDeMM0uZeF6FkkzLdlxDksa5coyP0sszUWj2bPu73ShQa29qDODFIPeCWJKVloZeTbBLmLTmACQcDHUAGuFbGwYKWQfxgRmKT+wl1AcoyDAOyB8ld/BTzxhNz+ureIA/alZrYtukA1hFrInVL63ymlr+T//w6l9HmU0hsopf+AUjqmUVr9WFgA7r8fOHHicm95Otx5J/D1U0t4DE/GYMB8RxW2PsQWj7iwEIy3ZVQFV1PHeEHuHg+huxTNYaGTveFYdmK1bW6eZ/u5fCifdS0jSk3vR9HzdHT18ZdXpQVVhdDF4nHu+7QQXsin8jzzskzpW9owsWVU5b5/P/DpTwNveEPxZ/m5O3sWcDCAfTDbCYkssJruQDqOvEi5yxBJvg85QUozwzLjlCINAvaQqwLXihm5+8l5DYcaTDRE7qJzlA/gscdY82VKgR/8AACw7i9jzd0u/oIZIFohIqqnLPco9mSG6tWGO+9kPz+GOzEIjSy5G0NshezmnNiWqWtBdVS5x3O5GZOmUg9lHDae4H1Bj+R75qYel4aK9X0dHWM8uVfy3BXVW0ruRojBkFfq3GbqrpTcSYgAdv777rijdL1AKveLPNFLLfcrMJ9P7uo1kLJllIVWAyFIAxVnLZM17BYIQ1pZeTtWzLK1FXIPhhosbYLkiQkgyT0kwIMPJn94/HFEEXBuuIS17k4j2zZNIIaO2G9m31py3wU4cQJ41jMifBR3YQAXrpm+ERwjwrYIp4OPcUv3KQVXk3KXnntAEA98bGMBC/PZxVpTiyuXMd1YDzCHbZhr2QQmILswN4p+YKJjjL8xKtkyKrnPFW+TherxBio7bNt2SRMKW0vOZdn28yBU9tktG4vadv7aAid3ghiGW53ce4HVmNVhGtxu4L55EJLqyt2hWeXepC2jdvx68EHIp93jj+PiRUa+B+ayIb+1bJsLprA3QRnVCdCS+y7BXa/R8Rd4Ac7iAFwrfSGrJWVtm4xdQFTD22pX7gHBzmk2TV1YzH63qVevUb1xLiwsPcC+qzxUrBeaqWYVRVhZYfZD2TNRVeuiQFju+5Q47KTDUPEYLaXW+6TrH8JaOdufw6KRDTsFAMzNoYseLAQgSjZVyppDIDcuXu8PzQatDtbmEUP2/WFIYGnVtiXJXfXch1pzDyK15+uDDwIvfCGLcPje97C+zv62Nj9+XWeqbVtjukDNiJbcdwnuuouFrQ3QgTuSzq4WshpXnwNIk3td9Tik5x5quPQEm6YuLGcfMuMWQVVsXCiuCAnwwlm0eH/7Qwtde/yNYRjApz4F/ON/XPwe0RQFGEfuETweqieV+xjPHWCNRyaN9hDkfi5YxJJdQDBcuVsIUqujqQe8TqUiFa/3hnZzatjkyp0TdOBFbAwV4Dg0Y8uEkQazoJXhrNB11swk6A+Bv/1bFt1w+DDw+OMJuS81s2wohJeod183WnLfJXjWs4Dj9hkAgDtS20QtQZuKlS5AynutqUdmotw1bK0zolncl1MyYBJy3ySFFSGB8Uke/chGp6AOzCjuuIOFnRZBJffUwucIXGsIj4f5+T2+oFpi44j+qg6ZnCDEQyOEhUW34POuiw76zK5TyD1lzSn15oVd0x9aMCuq6UlhCnLnqaV+P66cb+G6JMeW0Sor/2lgkiGCU2fZwuZttwHHjwOPP46zZ9nfGyN3uyX3awKEAHce/zIANjVVoXa1V0moCE0od+m5h1rShWk1S4LmSF2RMmxu6+XK3aClyr0XOeg4NZU0XrBy/595nxljJ+7A8xJyt0qyPIUtY1f0nFOfVSJeljoFnycEHSNgyl2ZGqSKx6nkzsfqxQ0qd4tFgdCAjfmi52KlW81Xdl1kyD2I9MaUO8AXvXf49n70RyW5r59h992Bfc1sW2Q2i6irutGS+y7CXc/8LoAx5F6iKgVSU/K6lXuoYescuxHUFntyexMUQ9roWVg2tgsTeVgGX4ktQ110OzVl4CrH1V4sXvn8yWPfwIC6uPtuJRSy5IFr6TwGXZt80Uz1zfMikwQ6RgibpL9fXZZR6wulShQ0RJiiQXs0CIAgwPpwHw4sV3u4OS5BBAPDnqLc4+ZsGUBENFnADTewENXjx4Ef/AA//P4QJgIsZyNQa4G4N1vlfg3gx24d4G78Jl5x46Op11Xus+bHp3CrETL1e+46Lp3PdmESmKSM6cbAwZJbTHrSu6VZAo+GFD6cvD7WU8Gcs1nECUIYc8Xkfsf1j+Id3f+Ie+4B3v9JZieVkzsjZXuKUD6ViJcWix9i/2Dls/gZ6w9TrxECWGAEqSYqqQ0zmiJMU1WkZ8+yNnX7q82w3A77rGg3CQBhrMPU6m9QLWBpQ3ad3XYbe+H4cfhDDR/8IPB8/BWIO2GYU0VIci/oAjUrWnLfRTCuO4TfxNvx1CNbqdfVKoWiYUQZUjdzTcpd0wCDDOEPddmFafFQllmtiso9DIGdoVtYERIQSR4W6DB78csWe916ooGIy+rmO/BQ+sSwbfy69et48YuB//l3TNKVzaaEcnf02cg9r5a7wOuPfB7/euG9mddFVqgapWOqXnxDPraleMnBqbPYxDLWDlebzTldtp+i3SQAhE3bMtqQzRAVcr8Pb8KpdRO/gneVJ0jMsl3R4m/Q2jJ7H2LFb4Rc1NolZZaBgKZBpqSrvu2scLSAkbvownQ4G1tYtdKdLPe7UHzTikW44SBLjP1zLPa4O1dTFo5tVyZ3Y7CND/7eAIdX2MJy2WxK+N32FESqLoou7is5j/PzuXUERGy5Su7WZVDuMqW/P8TZR9mJXjs2XpQAgMtDUr2d5HgFsSEfkk1gVLmHR67Hu/HLeN7RJ/ATuL8xchfCq/XcrwUcPsx+jlxMKXJfqnahWWB2R519J21tCG9oYOsSI9251eyDxjSBgI5fF5B1ZUr8TFH0LE/Z9C+yRV21E9FMcBw48Bi5l93ML3sZ4HlY+39+CZ/4xf+OX8P/hbmV4v0VOQq2MQW5q7bM/pJjOjeXG0QvFkwthVfVsrtNWR2mQu7rj7GciAMnyit3Crhz7HymlHusw9Sbs2VMLUKgucAznwkA+MBfnsD3cAL/+oYPgQCTZ59V3a7TrC3TXEmyFpPj2DH27+abUy+r5G4tVTOZTTKER+tV7rYewo8MXNrWMI9taHq2kJVpVCtjKsl9tXh8Fvey/SfOo7OW3lbvPFPNnYWaLmHHgY1LzMooU+633w68/e3Ae96DW171A9yCTwBOcSdJodwdfQpyV5pbLK6VEMyzn527LpGQe3L96J2E6c2G1LBo0B4Ohlj/PrPP1m7KKZ2QA5FM5vUUcqc6zClsraqwOgaChesA00QUAb/x/9p4jvFVvGL7Q+wNTSl3h9eSb8iWacl9N8F1gccfz7zsdBTlvlyN3C0SArRe5e7oQ/iRjq0dDYv6NoAccudhcKBJ4kweNi9EAHQsHyhejDzyIweBPwIe//QjWL4lXQVOeO7dxfrI3cE6J/f8uHuJd78b+PM/Bz7xCfnZIlg8AW0a5a56+Xm13CXe+c78bXNyV9ddiOvARIAQVmNqWCziB/0hzj7BSHnteDX1K5V7LxlbGBswKxSImxbWk65DsHQdAOD3fx/41reAjzz5D0Ae/SZ7Q0PKXQivoi5Qs6K1Za4C2Pwi0BDBWK5WpN4k3HMvSY2feBzGEH5kYmtgYMHIz5i0RKW7YTmZbfDuQksHi2+ck7ezG+6R/7Ge+ZtcUF2aMKe/CKrnPk6p2TbwoQ8l9QzKarIbTFHbxuQ3cEq5H5m8FZBIUrLURXXHSSy7hshd2A2BF2P9LHvAV+1B6i6wh/2gr9Rzp3oqVr9uWBZr/PIrvwL87M8Cz30ucOezvgds82qQTSl3saDqt+R+zcLm5Wir1HIXEDd2rZ67HsGLTWwNLCzkdGECmOc+hAnql8d1bzzByH35SLEivfGpBghiPPLV7JS8t8leq43cCYFNAkbuVYrA3HgjcN99wCtfWVq0Rih3Ncu4KlRyXzo2eVsxEQ2TCod1HBlFU7UkwMTbVbzk9YsmOtpgXLOsZHg829frJ4QXULNRz92yWPOl3/gN4M1vBh54ANCuP5a8oWlbpvXcr10I5V6llruAvLGbUO6BU5gOr9bLsErE5sZp9vnlY8UPK8cBTixt4JHTi4DnpabH/UuMoLr76psyH9efgA2v1E5K4TWvYf9KYHHXSa0PVBUiCocgxvyRycldzt4Kyb0pW4bbDYMI61sO1pwtANUI0l1kD7SBoh1CasA0mnkQAaz6xfIycM89wGtFD7nrr0/e0JQtI/q3NqTcW3K/CiAWmarUchcQYW519sh0jAh+bGIrdHFsJb8MqiT3XnmPmY1zIRwM4BzOL/cr8NQnh3jkSzcBX/5yqrVWf5vtX2elWohdFXxg5Z8CcQzg9bV9p/TcpyB33bVAEGMB29DMaguSKuQ1oJT/ZbYMizQyG7I6ZOs6L8bZ/jzW9hVUtMyBO8/GejnJ/d57mYu4tKS8ePy4MqimbBne9KX13K9diGJhk9kyXLXV2MXLNll/y61hJ7cLE1C90t3G+fKKkAInb53DN/EUxH/5YOr13ja7ITr7akpRBSvUVaUw2yQQyt2xJr+BiUZgIcCiPl2zCFHXJhUxdTlsGeEl7/hYH65gbbl66QXRnNzzkteaJve5uRFiBy4PufMyIWHQzL615H4VQKS3T6LcRdJHnT0ybTOGTy1sxXNYmMsnK5mdWBLeFcfAg99awTF8vxK5e3Dx/QceS73e53HQ3f31kTscpzwMcgqIRCy7YlXEzOcRYNGsrnxViDj2lDWnkntDhCmjQM5cxDrWcGC1+oNN8OhAJXeYcgZ02aCSe1Nx7m6ztszU5E4IuY4Q8jlCyDcIIV8nhNzNX18hhNxPCPkW/9lQ2Z1rB4LcJ/HchZ9ar3KPMaBOYRcmIJ3AUoQ//VPg6+v78U+M3yltMwcAJ1nfcDzyxXRJhj53hYRHWwtsu3aVJvpnTE3uJCyu5T7us3pOxJRhJNEyZkPkzrc3OL2J81jF2uHqNCN4dOAlnwlgwbzcBvLSUnKvNVV+oLt7lfsQwD+nlN4M4DYAP08IuRnAOwB8llJ6I4DP8t9bzADRPMKGX1lZCnKvU7k7ZozzYDHgi0v5Xr7oLlNky1DKwsSPd8/h9fsfGLt4Kcj94fOrrCs9R6/HCmMZZo1NQBtR7slXT/V5MsRiSXG1MshrYKQksfTiGyJMoUjPPBEhho6166qviwge9Xx+XuMYIcxar+PKEOq9KeXOz0vg7zJyp5SeppT+Df//NoCHARwBcCeA+/jb7gNw16yDvNYhkllsfVg5ksPSYxDE4zryTTYOK8ZFMBslrwsTML7S3ec/D/zlXwK/1HsnzB9/wdhtrq4C+xZDPIKTwBe+IF/vDwi6pOb2Zz/1U0m38pogyL0kFL4US0sUazdNHikDKLO3bhG5N6vcf3CW7fTakyrGQYJ1zTIQYuCz64gGISI067kX4vrr2QmctIVWRYiF57Ch5Ntant2EkOsBPAfAFwCsUUpP8z+dAVAxfaFFESS5G9XjYU1Hh0VCEFJfNInSohMLK/mXjqmknmdAKd795m9iP1bwv9+1Abz//ZW2e/JmHY88+FTgwU/K0MO+R9DRvTGfnBDvqH+SKdYgpiX3j/zFQSwtHZxu2/x6UePlAYXcG1LDktw32eL/gRsnezg5WoBBoFZMtCt3cqoVT3sa8JWvNPb1MvhgF9oyAABCyByA/wLgFyilKWOUUkoB5I6cEPI2QshDhJCHzp07N+sw9jScRcYMk2TpWU+7ITMdn3kcSsTHwr7875YJLDnk/rc/+x/xX79zEnc/70F0Pvz7lRnv5M0aHjGezhoYc/Q8A50GU9LrglTuznT20cmTwMHpuF1Gw1gj9eabWGxPbZfbMqeC/QAwkS0DAK7mwwv5oixvHm3Wab9Vxb/6V2ya2RDEtRE8+3mNfP9M5E4IMcGI/QOU0o/wl9cJIYf43w8BOJv3WUrpPZTSWymlt+7fv3+WYex5iBru9gQLYKZrptPO6xiHco8uHijonqQksKQQx/h3HziEOWOAn/uvr8IkftHJk8DZcAUX//rbcg7bD3R0jOm86MsJodwbsm3Lt83FgDWXPlciiqYx5c5toFM4CqB66QEBV/Mx4OQu7L0r4rl3u8DRo419vcEnv+FCecTYtJglWoYAeB+Ahyml/17508cBvIn//00APjb98FoAii0zwdTUNOu/IdTt53VhAhQfccRz9774VXzU/0n89AtPYXllMhX21Keyn9/0jgFf+hIAoB+Y6JpXAbnzmYxodn05IXxqtfsSe52Te42BRipEKOQpHIVJwmwM+Rg4eohBmE7NrzMZb7eAEEbwTXnus1xxLwDwvwJ4CSHkK/zfywH83wB+ghDyLQC3899bzADD0kAQT+Tbum79alG1FhYO5keVFJH7A7/zLexgHj/1s5OrFBkOiacCn/kMAKAXWuhYzTVwqAuilvqVJPfRZiJC0TdldQgi9uDigLNVuZqDgKuH8IbpcrhXRLlfBvyjf8QKlTWBqRdUKaWfB1B02l467fe2yIIQwIGXqss9Dr/0S8Ab3lDvONSHRV4XJkAh95HEjD/5dAfz2g5e8trycgN5EEELj6z8OPCZe4Bf/VX0IwsH7JoXVBuAsMZE5uVl3baZT+5S0TekhtXcirW5HoDJHuiuEWIw5DHgXv2Z1rsJv/VbzX13m6F6lcC2KOzrq6+s3XwzcMcdNY+BcwRBjLm1/PA2WQxJUe7RVg8fP30rXn7jY1NFjeg6cNNNwCPzz2WLqpcuoR/Z6DqXOWtxCiwuMCItygtoElK5Lzi5rzdF7oYiGdeWJrfOHGMIL+Ix4Hztpq5ewNcS2iN2leBd7+nizb9+wxUdg7BlWBemgiQmJ9uA4MF7voqzWMNdr5n+cjt5Enh4cByIIuBzn0M/dtC5Csj9eS+0cD9ux9970eWv0SeUu7mQXh8RyUtNkTshgMmzYNf2T36OXHOIQcSkeuK51ze+awUtuV8l+LmfS5qzXykI33hBz68ICSj1MpTY3T/54AAmArz87hun3vbJk8B3TrvwuyvApz6FHrp1J5M2AvKcZ+P2h38L5Lm3XvZt33Xzo/iXeBf0uTS5S9JvcJFSNOc+cHByimHkzqZ4Cbm3VDUp2iPWojKEb7xgFBeykpXuuOdOKfDRv7sBL933t4URNlXwjGcAUUTwxWe9FfjYx9BHp3IDiCsOsSJ8mXHL3T+Gd71bB7FGMlS5Cm7S6hDkvnbd5JLbsVj1UUDx3CdYb2rB0JJ7i8oQtsyiWZz2P1rp7uufPYNvh8fwUy/enGnbr3gFq3Z87/DNCM9tIISFzlx7w5fi6U/PzboVir1J5S6ac6+dmHx65VoxBjFT7sLeaz33ydEesRaVIW0ZuzgzdLTS3Z/8pydAEOPVP3/dTNvudoE3vhH446/ehB/iMACgM9devtPAuhzKnXcCW5uw9ADAMqEHlC0CC5HQkvvkaI9Yi8qwO2yxdMEtzrqQle44uX/0z5dxm/k3OPi/PGXm7b/1rawU7O8u/h8AgO58jVXRriEI/7pZW4aR+4Gjk9syrhPDgwNQ2pL7DGiPWIvKcHij7qIuTEB6QfWJv/ge/mbjSXj1j5yq3pe0BD/yI8AttwC/47ME6M7iHs1saRjSlqmxeXpmG0K5T1E20LUpBuiADqOW3GdAe8RaVIZQ7otzxZmhSaU74FO/cD8A4FW/8fdqG8Nb3wqc91i1wc6Bkg7cLQph8bWTRpW7SaEhwurq5J91HDbr2zrn4w/uZ7kdi5O3kL3m0ZJ7i8qQtkxBFyYgSRMPv3sKn3joIK5f2sDNP36gtjG88Y1Ap8O23735+Jh3t8iDabPz2KRyt550FKurZKp+Ai7PuXrxHQY+9OeH8E78Kk7eUDxbbJGPltxbVIYzxyyXhcVii0Us1l363kX8N9yOV72+W4cjI7GwALz+9ewLr4Y4990IodgbtWVcc6oYdyDpxvTI1yP8MV6LX739r4CnzL5mc63h8qfNtbhqceCmJZzUvolbXlAcr67rrDzBp/H34cHFK19T/zje/nbgi19s7/dpYR5iXol5oLn2xk9+8vQNjJ77Qhs/9qH/iff+/T/Fc971y2yxpcXEIKyfxpXFrbfeSh966KErPYwWVSCulxI5bhMfAWzMzVGcP0+m7kLUohn87u8Cb3sbq558yy3NbKPCZVKOOG6svd1eAiHkS5TS3PTn9ui1mAyEjL1jxXT/jjtaYt+NEOsiTZbRrXCZlKMl9pnRHsEWtcN0mNv3qldd4YG0yMU8CzbCXBtstKfRknuL2mFZTLW9/OVXeiQt8vDqVwP33w+cOHGlR9KiSbTk3qJ2mCbwoz8KHKgvArJFjTBN4Pbbr/QoWjSNNlqmRe34tV9j0RItWrS4cmjJvUXteOtbr/QIWrRo0ZgtQwj5SULINwkhjxFCsnVHW7Ro0aJFY2iE3AkhOoD/BOBlAG4G8NOEkJub2FaLFi1atMiiKeX+PACPUUq/QykNAHwIwJ0NbatFixYtWoygKXI/AuAHyu+n+GstWrRo0eIy4IqFQhJC3kYIeYgQ8tC5c+eu1DBatGjRYk+iKXJ/AoDaV+0of02CUnoPpfRWSumt+/fvb2gYLVq0aHFtoily/2sANxJCThBCLABvAPDxhrbVokWLFi1G0EicO6V0SAj5JwA+DUAH8HuU0q83sa0WLVq0aJHFrij5Swg5B+DxKT++CuB8jcO5WnAt7ve1uM/Atbnf1+I+A5Pv93FKaa6vvSvIfRYQQh4qqme8l3Et7ve1uM/Atbnf1+I+A/Xud1s4rEWLFi32IFpyb9GiRYs9iL1A7vdc6QFcIVyL+30t7jNwbe73tbjPQI37fdV77i1atGjRIou9oNxbtGjRosUIWnJv0aJFiz2Iq5rcr4Wa8YSQ6wghnyOEfIMQ8nVCyN389RVCyP2EkG/xn8tXeqxNgBCiE0K+TAj5JP/9BCHkC/yc/xHPgN4zIIQsEUI+TAh5hBDyMCHk+dfCuSaEvJ1f318jhHyQEOLsxXNNCPk9QshZQsjXlNdyzy9h+A98/79KCLllkm1dteR+DdWMHwL455TSmwHcBuDn+X6+A8BnKaU3Avgs/30v4m4ADyu//1sA76GU3gBgA8BbrsiomsN7AfwZpfQkgGeB7fuePteEkCMA/hmAWymlTwfLan8D9ua5/s8AfnLktaLz+zIAN/J/bwPw25Ns6Kold1wjNeMppacppX/D/78NdrMfAdvX+/jb7gNw15UZYXMghBwF8AoA9/LfCYCXAPgwf8ue2m9CyCKAFwF4HwBQSgNK6SaugXMNVgrFJYQYADoATmMPnmtK6f8AcHHk5aLzeyeA36cMDwJYIoQcqrqtq5ncr7ma8YSQ6wE8B8AXAKxRSk/zP50BsHaFhtUkfhPAvwAQ89/3AdiklA7573vtnJ8AcA7A+7kVdS8hpIs9fq4ppU8A+HcAvg9G6pcAfAl7+1yrKDq/M3Hc1Uzu1xQIIXMA/guAX6CUbql/oyyedU/FtBJCXgngLKX0S1d6LJcRBoBbAPw2pfQ5AHoYsWD26LleBlOpJwAcBtBF1rq4JlDn+b2ayX1szfi9AkKICUbsH6CUfoS/vC6maPzn2Ss1vobwAgCvJoR8D8xyewmYH73Ep+7A3jvnpwCcopR+gf/+YTCy3+vn+nYA36WUnqOUhgA+Anb+9/K5VlF0fmfiuKuZ3K+JmvHcZ34fgIcppf9e+dPHAbyJ//9NAD52ucfWJCilv0wpPUopvR7s3D5AKf2HAD4H4LX8bXtqvymlZwD8gBDyFP7SSwF8A3v8XIPZMbcRQjr8ehf7vWfP9QiKzu/HAfxvPGrmNgCXFPtmPCilV+0/AC8H8CiAbwP4lSs9nob28YVg07SvAvgK//dyMP/5swC+BeC/AVi50mNt8Bj8OIBP8v8/CcAXATwG4I8B2Fd6fDXv67MBPMTP90cBLF8L5xrAOwE8AuBrAP4AgL0XzzWAD4KtK4RgM7W3FJ1fAAQsIvDbAP4OLJqo8rba8gMtWrRosQdxNdsyLVq0aNGiAC25t2jRosUeREvuLVq0aLEH0ZJ7ixYtWuxBtOTeokWLFnsQLbm3aNGixR5ES+4tWrRosQfx/wMaLyH7AbMfjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot true and predicted RUL values\n",
    "plt.plot(true_rul, label = \"True RUL\", color = \"red\")\n",
    "plt.plot(preds_for_last_example, label = \"Pred RUL\", color = \"blue\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95qDI_iTAnLs"
   },
   "source": [
    "It is very likely that readers may get sligtly different results while running this notebook on their system. This happens because of the nondeterministic nature of some deep learning operations and dependence of libraries like `Tensorflow` on computer architecture. Therefore, to make our results reproducible, we also share saved models of all our notebooks. All saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/tree/master/saved_models/cmapss). A notebook describing the procedure to use the saved models can be found [here](https://github.com/biswajitsahoo1111/rul_codes_open/blob/master/notebooks/cmapss_notebooks/CMAPSS_using_saved_model_deep_learning.ipynb). As a final note remember that hyperparameter tuning is more of an art than science. It is possible to obtain better results than what has been obtained here by choosing better set of hyperparameters.\n",
    "\n",
    "For other reproducible results on RUL, interested readers can visit my [project page](https://biswajitsahoo1111.github.io/rul_codes_open). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w_h0wUc95uCN"
   },
   "source": [
    "CNN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ojel3z2JAnLw"
   },
   "outputs": [],
   "source": [
    "cnn2=models.Sequential([\n",
    "    #layers.Masking(mask_value=-99., input_shape=(sequence_length, train_array.shape[2])),\n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu', input_shape=(window_length, processed_train_data.shape[2])),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "     layers.Flatten(),\n",
    "     # dense\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1, activation=\"linear\")])\n",
    "    \n",
    "cnn2.compile(optimizer='adam',loss='mean_squared_error')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICB95tm8AnLw",
    "outputId": "c6d15b7c-2b50-4672-96ba-fa612dbea6cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3 (Conv1D)           (None, 28, 32)            1376      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 4, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 2, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,033\n",
      "Trainable params: 16,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ShEVOfc6AnLw",
    "outputId": "05ba9b79-17cb-4699-a5bf-5e7ffb2f707c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "444/444 [==============================] - 4s 7ms/step - loss: 947.4249 - val_loss: 336.4026\n",
      "Epoch 2/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 293.1439 - val_loss: 251.9537\n",
      "Epoch 3/30\n",
      "444/444 [==============================] - 3s 7ms/step - loss: 242.7506 - val_loss: 229.9311\n",
      "Epoch 4/30\n",
      "444/444 [==============================] - 3s 7ms/step - loss: 223.4310 - val_loss: 243.8540\n",
      "Epoch 5/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 213.4959 - val_loss: 220.5168\n",
      "Epoch 6/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 198.3341 - val_loss: 237.5257\n",
      "Epoch 7/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 188.5126 - val_loss: 238.6486\n",
      "Epoch 8/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 184.1386 - val_loss: 224.8402\n",
      "Epoch 9/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 179.2453 - val_loss: 191.2244\n",
      "Epoch 10/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 172.9431 - val_loss: 242.0004\n",
      "Epoch 11/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 165.5938 - val_loss: 169.0548\n",
      "Epoch 12/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 157.2633 - val_loss: 160.3322\n",
      "Epoch 13/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 151.3575 - val_loss: 168.0728\n",
      "Epoch 14/30\n",
      "444/444 [==============================] - 3s 7ms/step - loss: 148.4289 - val_loss: 149.0252\n",
      "Epoch 15/30\n",
      "444/444 [==============================] - 3s 7ms/step - loss: 142.5619 - val_loss: 147.5647\n",
      "Epoch 16/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 138.4388 - val_loss: 145.7259\n",
      "Epoch 17/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 134.3085 - val_loss: 137.6453\n",
      "Epoch 18/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 129.9840 - val_loss: 142.0670\n",
      "Epoch 19/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 127.2219 - val_loss: 164.5542\n",
      "Epoch 20/30\n",
      "444/444 [==============================] - 3s 7ms/step - loss: 120.2633 - val_loss: 129.6172\n",
      "Epoch 21/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 116.7556 - val_loss: 125.0218\n",
      "Epoch 22/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 114.8640 - val_loss: 129.4354\n",
      "Epoch 23/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 113.8341 - val_loss: 158.0824\n",
      "Epoch 24/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 110.6597 - val_loss: 201.8342\n",
      "Epoch 25/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 103.2389 - val_loss: 135.2897\n",
      "Epoch 26/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 104.2675 - val_loss: 119.8522\n",
      "Epoch 27/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 98.1378 - val_loss: 139.6012\n",
      "Epoch 28/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 96.1520 - val_loss: 115.1749\n",
      "Epoch 29/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 91.6191 - val_loss: 143.5206\n",
      "Epoch 30/30\n",
      "444/444 [==============================] - 3s 6ms/step - loss: 87.2237 - val_loss: 102.8473\n"
     ]
    }
   ],
   "source": [
    "history2 = cnn2.fit(processed_train_data, processed_train_targets,\n",
    "                    validation_data=(processed_val_data, processed_val_targets),\n",
    "                    epochs=30,\n",
    "                   batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "110YPlGFbhxp",
    "outputId": "f8514ca5-f604-4026-b252-740c5bfa83e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ae4b4c715e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Fit the pipeline to the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocessed_train_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Print the best parameters and best score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mcloned_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcloned_parameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mPipeline\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    246\u001b[0m                     \u001b[0;34m\"Invalid parameter %s for estimator %s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                     \u001b[0;34m\"Check the list of available parameters \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter filters for estimator Pipeline(steps=[('cnn2',\n                 <keras.engine.sequential.Sequential object at 0x7faa903dbcd0>)]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    \n",
    "    ('cnn2',cnn2)\n",
    "])\n",
    "\n",
    "# Define the hyperparameters and possible values\n",
    "param_grid = {\n",
    "    'filters': [32, 64, 128],\n",
    "    'kernel_size': [3, 5, 7],\n",
    "    'pool_size': [2, 3]\n",
    "}\n",
    "\n",
    "# Create the grid search object\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "grid.fit(processed_train_data,processed_train_targets)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters: \", grid.best_params_)\n",
    "print(\"Best MSE: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "GD3AnjPCAnLx",
    "outputId": "d78d4443-f18a-4736-e83f-2de3d9767a41"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "gW-kzHP6AnLx"
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_hat, label='test'):\n",
    "    mse = mean_squared_error(y_true, y_hat)\n",
    "    rmse = np.sqrt(mse)\n",
    "    variance = r2_score(y_true, y_hat)\n",
    "    print('{} set RMSE:{}, R2:{}'.format(label, rmse, variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xy5mjm3YAnLx",
    "outputId": "497efd2d-9e09-4e78-e696-e39ce7a9d48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "rul_pred = cnn2.predict(processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FpEaBBVAnLy",
    "outputId": "accc64c6-67a8-4a16-c394-456d4ffa736b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  15.229597950291504\n"
     ]
    }
   ],
   "source": [
    "preds_for_each_engine = np.split(rul_pred, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine,weights=np.repeat(1/num_windows, num_windows),axis=0)\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AfelCvGUAnLy",
    "outputId": "0b5efbdc-2fa9-416a-8b9a-b0ff6764b530"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Taking only last examples):  15.14816552583477\n"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFSRsnpmAnLy",
    "outputId": "0a9aac94-96b9-4b6f-b75b-f498dbf52ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set RMSE:15.229597950291504, R2:0.8656872217059567\n"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate(true_rul, mean_pred_for_each_engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxJBausOAnLy",
    "outputId": "e77853b8-65db-4ad5-e185-3ea5abe342c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_3_input (InputLayer)  [(None, 30, 14)]         0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 28, 32)            1376      \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 6, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 4, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 2, 32)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,584\n",
      "Trainable params: 7,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "flatten_layer_model = tf.keras.Model(inputs=cnn2.input,\n",
    "                                     outputs=cnn2.get_layer(\"flatten_1\").output)\n",
    "flatten_layer_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vucMylrvFFj4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "LH6gGHgGFVqv"
   },
   "outputs": [],
   "source": [
    "flatten_layer_model.compile(optimizer='adam',loss='mean_squared_error')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "hcfybrWnFHyu",
    "outputId": "b02f9d55-a6d9-43ff-aed0-4af7b755f386"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f07cbaea46fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflatten_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_train_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessed_train_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "flatten_layer_model.fit(processed_train_data, processed_train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "byTXUhIHAnLz",
    "outputId": "90ce8cef-def8-423f-d75e-2f0b19faea3a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-dd4b14beba9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhope_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_layer_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pop from an empty set'"
     ]
    }
   ],
   "source": [
    "hope_test = flatten_layer_model.predict(processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "J9uVvpL8AnLz",
    "outputId": "94ecd504-f89d-4cde-d97f-f03871a3df1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(497, 64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hope_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCxzUYp8AnLz",
    "outputId": "43322cb1-4d9d-4669-ac8b-f6a1d8d71c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "hope_train = flatten_layer_model.predict(processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "0juw_SWDAnLz"
   },
   "outputs": [],
   "source": [
    "array = processed_train_targets.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i74jEgKB6UU0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G-XcS7_3AnL0",
    "outputId": "ae896db1-ac47-4f66-d7ef-91a3f40dd3ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_reg_model =SVR()\n",
    "best_reg_model.fit(hope_train,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZlCCN264TOi",
    "outputId": "cc5ba8da-4987-4989-e467-e251d067526a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVR_model.sav']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'SVR_model.sav'\n",
    "joblib.dump(best_reg_model, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "ENCknjiIAnL0"
   },
   "outputs": [],
   "source": [
    "y_pred =best_reg_model.predict(hope_train)\n",
    "#evaluate(label_array, y_pred, 'train')\n",
    "\n",
    "#y_hat_test =best_reg_model.predict(featuers_flat_test)\n",
    "#evaluate(y_test, y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9N3-lhZAnL0",
    "outputId": "a4194a52-35e2-4971-cceb-0ede2efaa75a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:10.132629360080916, R2:0.9412477068729744\n"
     ]
    }
   ],
   "source": [
    "evaluate(processed_train_targets, y_pred, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "PKxT0t7jAnL1"
   },
   "outputs": [],
   "source": [
    "y_pred_test =best_reg_model.predict(hope_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8iJ4-HdAnL1",
    "outputId": "593df5c3-1db0-464b-c1ea-811e2e9f3b2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  16.226364590150027\n"
     ]
    }
   ],
   "source": [
    "preds_for_each_engine = np.split(y_pred_test, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine,weights=np.repeat(1/num_windows, num_windows),axis=0)\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl5obEIFAnL1",
    "outputId": "90e1c88c-af93-46ee-919c-4bf10da6339b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Taking only last examples):  15.794246619958141\n"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrxjYN5wAnL2",
    "outputId": "46060c31-89a7-431a-bbd3-082069f36169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set RMSE:16.241519554026567, R2:0.847245583902903\n"
     ]
    }
   ],
   "source": [
    "evaluate(true_rul,mean_pred_for_each_engine, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fm-qq7IAnL2",
    "outputId": "5f753055-1cee-49fa-e1bb-b693c7b0c6d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['flatten_layer_model.sav']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'flatten_layer_model.sav'\n",
    "joblib.dump(flatten_layer_model, filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQAZ0TGRAnL2",
    "outputId": "3879e59d-9ded-4b6b-83b8-50b7d2c04f53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVR_model.sav']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "# save the model to disk\n",
    "filename = 'SVR_model.sav'\n",
    "joblib.dump(best_reg_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PiLsfBiAnL3"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0fTSfzR9zPf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iuqaW_NR9zS-",
    "outputId": "a7c10f18-a159-4173-e264-cc439a637204"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "<ipython-input-83-75cafc97d59d>:31: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
      "<ipython-input-83-75cafc97d59d>:14: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-75cafc97d59d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mloaded_model_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flatten_layer_model.sav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m data_preprocessing = Pipeline([\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         ):\n\u001b[0;32m--> 220\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;34m\"Last step of Pipeline should implement fit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;34m\"or be the string 'passthrough'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Last step of Pipeline should implement fit or be the string 'passthrough'. '(array([[[-1.        ,  0.09036145, -0.37867888, ..., -0.33333333,\n          0.11627907,  0.3236675 ],\n        [-0.99445983, -0.69879518, -0.24089819, ..., -0.16666667,\n          0.36434109,  0.37365369],\n        [-0.98891967, -0.24698795, -0.30673643, ..., -0.16666667,\n          0.45736434,  0.44269539],\n        ...,\n        [-0.85041551, -0.56626506,  0.01199041, ..., -0.33333333,\n          0.06976744,  0.25932063],\n        [-0.84487535, -0.55421687, -0.29758012, ..., -0.33333333,\n          0.36434109,  0.29218448],\n        [-0.83933518, -0.04819277, -0.35993024, ..., -0.5       ,\n          0.47286822,  0.41590721]],\n\n       [[-0.99445983, -0.69879518, -0.24089819, ..., -0.16666667,\n          0.36434109,  0.37365369],\n        [-0.98891967, -0.24698795, -0.30673643, ..., -0.16666667,\n          0.45736434,  0.44269539],\n        [-0.9833795 , -0.25903614, -0.42969261, ..., -0.5       ,\n          0.33333333,  0.32421983],\n        ...,\n        [-0.84487535, -0.55421687, -0.29758012, ..., -0.33333333,\n          0.36434109,  0.29218448],\n        [-0.83933518, -0.04819277, -0.35993024, ..., -0.5       ,\n          0.47286822,  0.41590721],\n        [-0.83379501, -0.1746988 , -0.55613691, ..., -0.16666667,\n          0.03875969,  0.27312897]],\n\n       [[-0.91689751, -0.19879518, -0.23915413, ..., -0.16666667,\n          0.11627907,  0.28914664],\n        [-0.91135734, -0.57831325, -0.46806191, ..., -0.33333333,\n         -0.11627907,  0.01049434],\n        [-0.90581717, -0.25301205,  0.09657728, ..., -0.33333333,\n          0.06976744, -0.08146921],\n        ...,\n        [-0.76731302, -0.03012048, -0.24307826, ..., -0.33333333,\n         -0.08527132,  0.05854736],\n        [-0.76177285, -0.06024096, -0.0970133 , ..., -0.33333333,\n          0.00775194,  0.2678818 ],\n        [-0.75623269, -0.23493976, -0.15064312, ..., -0.33333333,\n          0.25581395,  0.09472521]],\n\n       ...,\n\n       [[-0.08033241, -0.12650602, -0.13887072, ...,  0.16666667,\n          0.2248062 ,  0.25545429],\n        [-0.07479224,  0.04216867, -0.38434707, ..., -0.16666667,\n          0.28682171,  0.18254626],\n        [-0.06925208, -0.30722892, -0.11881404, ..., -0.33333333,\n          0.06976744,  0.1996686 ],\n        ...,\n        [ 0.06925208,  0.22289157,  0.23871812, ...,  0.        ,\n         -0.20930233, -0.16266225],\n        [ 0.07479224,  0.21084337,  0.07477654, ...,  0.16666667,\n         -0.33333333,  0.0574427 ],\n        [ 0.08033241,  0.34337349, -0.03597122, ...,  0.16666667,\n         -0.25581395, -0.1413974 ]],\n\n       [[-0.07479224,  0.04216867, -0.38434707, ..., -0.16666667,\n          0.28682171,  0.18254626],\n        [-0.06925208, -0.30722892, -0.11881404, ..., -0.33333333,\n          0.06976744,  0.1996686 ],\n        [-0.06371191, -0.10240964, -0.17680401, ..., -0.16666667,\n          0.14728682,  0.11516156],\n        ...,\n        [ 0.07479224,  0.21084337,  0.07477654, ...,  0.16666667,\n         -0.33333333,  0.0574427 ],\n        [ 0.08033241,  0.34337349, -0.03597122, ...,  0.16666667,\n         -0.25581395, -0.1413974 ],\n        [ 0.08587258,  0.23493976,  0.0442555 , ...,  0.16666667,\n         -0.19379845,  0.03755869]],\n\n       [[-0.06925208, -0.30722892, -0.11881404, ..., -0.33333333,\n          0.06976744,  0.1996686 ],\n        [-0.06371191, -0.10240964, -0.17680401, ..., -0.16666667,\n          0.14728682,  0.11516156],\n        [-0.05817175, -0.02409639, -0.31981687, ..., -0.33333333,\n          0.08527132, -0.12703673],\n        ...,\n        [ 0.08033241,  0.34337349, -0.03597122, ...,  0.16666667,\n         -0.25581395, -0.1413974 ],\n        [ 0.08587258,  0.23493976,  0.0442555 , ...,  0.16666667,\n         -0.19379845,  0.03755869],\n        [ 0.09141274,  0.04819277,  0.33333333, ...,  0.33333333,\n         -0.13178295, -0.1955261 ]]]), array([112,  98,  69,  82,  91,  93,  91,  95, 111,  96,  97, 124,  95,\n       107,  83,  84,  50,  28,  87,  16,  57, 111, 113,  20, 145, 119,\n        66,  97,  90, 115,   8,  48, 106,   7,  11,  19,  21,  50, 142,\n        28,  18,  10,  59, 109, 114,  47, 135,  92,  21,  79, 114,  29,\n        26,  97, 137,  15, 103,  37, 114, 100,  21,  54,  72,  28, 128,\n        14,  77,   8, 121,  94, 118,  50, 131, 126, 113,  10,  34, 107,\n        63,  90,   8,   9, 137,  58, 118,  89, 116, 115, 136,  28,  38,\n        20,  85,  55, 128, 137,  82,  59, 117,  20]), [2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5])' (type <class 'tuple'>) doesn't"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    " \n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets\n",
    "\n",
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "    \n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows\n",
    "\n",
    "#applying every things \n",
    "columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\"]\n",
    "train_data =pd.read_csv(\"/content/drive/MyDrive/Project/data/train_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "test_data =pd.read_csv(\"/content/drive/MyDrive/Project/data/test_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "true_rul = pd.read_csv(\"/content/drive/MyDrive/Project/data/RUL_FD001.txt\", sep= \"\\s+\", header = None) \n",
    "\n",
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125            \n",
    "\n",
    "\n",
    "#\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped =['id','op1','op2','op3', 'sensor1', 'sensor5', 'sensor6','sensor7','sensor10',\n",
    "                 'sensor16', 'sensor18', 'sensor19']\n",
    "\n",
    "\n",
    "test_data_first_column = test_data['id']\n",
    "\n",
    "# Scale data for all engines\n",
    "scaler = MinMaxScaler(feature_range = (-1,1))\n",
    "\n",
    "train_data = scaler.fit_transform(train_data.drop(columns = columns_to_be_dropped))\n",
    "test_data = scaler.transform(test_data.drop(columns = columns_to_be_dropped))\n",
    "\n",
    "\n",
    "test_data = pd.DataFrame(data = np.c_[test_data_first_column, test_data])\n",
    "\n",
    "\n",
    "num_test_machines = len(test_data[0].unique())\n",
    "\n",
    "\n",
    "\n",
    "def process_test_data_for_multiple_engines(test_data, num_test_machines, window_length, shift, num_test_windows, true_rul):\n",
    "    processed_test_data = []\n",
    "    num_test_windows_list = []\n",
    "    \n",
    "    for i in np.arange(1, num_test_machines + 1):\n",
    "        temp_test_data = test_data[test_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "        # Verify if data of given window length can be extracted from test data\n",
    "        if (len(temp_test_data) < window_length):\n",
    "            print(\"Test engine {} doesn't have enough data for window_length of {}\".format(i, window_length))\n",
    "            raise AssertionError(\"Window length is larger than number of data points for some engines. \"\n",
    "                                 \"Try decreasing window length.\")\n",
    "\n",
    "        # Prepare test data\n",
    "        test_data_for_an_engine, num_windows = process_test_data(temp_test_data, window_length = window_length, shift = shift,\n",
    "                                                                 num_test_windows = num_test_windows)\n",
    "\n",
    "        processed_test_data.append(test_data_for_an_engine)\n",
    "        num_test_windows_list.append(num_windows)\n",
    "\n",
    "    processed_test_data = np.concatenate(processed_test_data)\n",
    "    true_rul = true_rul[0].values\n",
    "    \n",
    "    return processed_test_data, true_rul, num_test_windows_list\n",
    "\n",
    "# load trained models \n",
    "loaded_model_SVR = joblib.load('SVR_model.sav')\n",
    "loaded_model_CNN = joblib.load('flatten_layer_model.sav')\n",
    "\n",
    "data_preprocessing = Pipeline([\n",
    "    \n",
    "    \n",
    "    ('process_test_data', process_test_data_for_multiple_engines(test_data, num_test_machines, window_length, shift, num_test_windows, true_rul))\n",
    "])\n",
    "model_pipeline = Pipeline([\n",
    "    ('flatten_layer',loaded_model_CNN),\n",
    "    ('regressor',loaded_model_SVR)\n",
    "])\n",
    "clf=Pipeline([\n",
    "        (\"data_preprocessing\",data_preprocessing),\n",
    "        (\"model_pipeline\",model_pipeline)\n",
    "\n",
    "    ])\n",
    "        \n",
    "\n",
    "\n",
    "y_pred_class= clf.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IylqCchv9zWq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wiHyLCq9zfB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE8m0yd_9zjo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zEO_NkI59zoi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipTCnrFV9zt1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFf7hf7d9zzy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qCpREaNm9z4Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHbrNHE39z9W"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGDKfoE590BZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RqX79zmO90Fp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EqmX36bB90LQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3izQ0jFL90Pp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNxPPJhY90VQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MXP1zggj90ar"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljjxQnJl90fz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "Tt0lU9BLAnL3"
   },
   "outputs": [],
   "source": [
    "cnn3=models.Sequential([\n",
    "    #layers.Masking(mask_value=-99., input_shape=(sequence_length, train_array.shape[2])),\n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu', input_shape=(window_length, processed_train_data.shape[2])),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "    layers.Conv1D(filters=32,kernel_size=3,activation='relu'),\n",
    "    layers.MaxPooling1D(2),\n",
    "    \n",
    "     layers.Flatten()])\n",
    "     # dense\n",
    "   \n",
    "    \n",
    "cnn3.compile(optimizer='adam',loss='mean_squared_error') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "aOObJsjyAnL3",
    "outputId": "e9671a78-38a6-4155-e5ae-ac7d42f56625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_18 (Conv1D)          (None, 28, 32)            1376      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPoolin  (None, 14, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_19 (Conv1D)          (None, 12, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_16 (MaxPoolin  (None, 6, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_20 (Conv1D)          (None, 4, 32)             3104      \n",
      "                                                                 \n",
      " max_pooling1d_17 (MaxPoolin  (None, 2, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,584\n",
      "Trainable params: 7,584\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_DchJQf6AnL3",
    "outputId": "61659c87-7951-4511-ad01-64b12fad68bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 2923.0371 - val_loss: 1266.0664\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1269.2125 - val_loss: 1245.7195\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1255.3235 - val_loss: 1237.5610\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1246.9271 - val_loss: 1231.4462\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1239.9019 - val_loss: 1216.8882\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1211.3361 - val_loss: 1182.6838\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 992.2008 - val_loss: 914.7501\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 909.4905 - val_loss: 896.9733\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 887.1828 - val_loss: 866.9600\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 865.0187 - val_loss: 845.6252\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 848.2374 - val_loss: 829.1554\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 836.5444 - val_loss: 820.5349\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 824.9395 - val_loss: 807.4032\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 818.4083 - val_loss: 800.8484\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 810.9858 - val_loss: 795.7463\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 805.2631 - val_loss: 791.1060\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 801.2988 - val_loss: 783.8364\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 795.5039 - val_loss: 779.8378\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 791.7578 - val_loss: 776.1411\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 788.3715 - val_loss: 774.7870\n",
      "Epoch 21/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 784.5708 - val_loss: 770.3423\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 781.7672 - val_loss: 771.7920\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 779.1278 - val_loss: 766.6886\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 777.7546 - val_loss: 768.8920\n",
      "Epoch 25/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 776.1716 - val_loss: 761.5118\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 776.6021 - val_loss: 760.1640\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 772.6441 - val_loss: 777.0919\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 770.5176 - val_loss: 757.4411\n",
      "Epoch 29/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 769.4454 - val_loss: 755.9549\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 766.4235 - val_loss: 763.6224\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 767.0364 - val_loss: 752.4453\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 763.6378 - val_loss: 753.1779\n",
      "Epoch 33/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 762.2518 - val_loss: 751.0234\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 760.8683 - val_loss: 751.3849\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 761.1415 - val_loss: 748.5024\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 758.9538 - val_loss: 746.5522\n",
      "Epoch 37/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 755.6923 - val_loss: 748.4886\n",
      "Epoch 38/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 755.7040 - val_loss: 744.8405\n",
      "Epoch 39/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 754.8673 - val_loss: 744.1507\n",
      "Epoch 40/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 753.3620 - val_loss: 742.4691\n",
      "Epoch 41/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 750.9886 - val_loss: 766.5711\n",
      "Epoch 42/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 752.2717 - val_loss: 741.2791\n",
      "Epoch 43/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 748.7521 - val_loss: 739.1119\n",
      "Epoch 44/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 749.6646 - val_loss: 740.1650\n",
      "Epoch 45/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 749.3054 - val_loss: 744.0070\n",
      "Epoch 46/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 747.4587 - val_loss: 751.6417\n",
      "Epoch 47/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 745.3654 - val_loss: 737.9948\n",
      "Epoch 48/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 742.7296 - val_loss: 758.2156\n",
      "Epoch 49/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 742.6063 - val_loss: 735.3790\n",
      "Epoch 50/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 740.7724 - val_loss: 737.4590\n",
      "Epoch 51/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 740.0311 - val_loss: 734.7377\n",
      "Epoch 52/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 738.5229 - val_loss: 732.8685\n",
      "Epoch 53/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 739.6680 - val_loss: 739.3040\n",
      "Epoch 54/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 736.0013 - val_loss: 731.0928\n",
      "Epoch 55/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 736.2083 - val_loss: 730.5868\n",
      "Epoch 56/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 735.5790 - val_loss: 728.7868\n",
      "Epoch 57/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 734.2995 - val_loss: 728.8478\n",
      "Epoch 58/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 733.0359 - val_loss: 727.0275\n",
      "Epoch 59/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 731.3459 - val_loss: 730.7086\n",
      "Epoch 60/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 732.7654 - val_loss: 725.7514\n",
      "Epoch 61/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 731.8224 - val_loss: 732.2492\n",
      "Epoch 62/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 730.1715 - val_loss: 723.6400\n",
      "Epoch 63/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 730.4788 - val_loss: 725.8394\n",
      "Epoch 64/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 725.9454 - val_loss: 722.1416\n",
      "Epoch 65/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 727.8005 - val_loss: 720.2086\n",
      "Epoch 66/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 728.1864 - val_loss: 725.4257\n",
      "Epoch 67/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 724.8181 - val_loss: 719.4221\n",
      "Epoch 68/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 726.0119 - val_loss: 719.4918\n",
      "Epoch 69/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 723.9521 - val_loss: 726.5676\n",
      "Epoch 70/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 723.9999 - val_loss: 720.8625\n",
      "Epoch 71/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 723.0762 - val_loss: 724.8798\n",
      "Epoch 72/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 722.8895 - val_loss: 727.3660\n",
      "Epoch 73/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 721.0616 - val_loss: 733.0305\n",
      "Epoch 74/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 719.7582 - val_loss: 714.4279\n",
      "Epoch 75/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 719.5995 - val_loss: 726.4217\n",
      "Epoch 76/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 719.2569 - val_loss: 714.4434\n",
      "Epoch 77/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 718.7180 - val_loss: 723.3187\n",
      "Epoch 78/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 718.9584 - val_loss: 714.1424\n",
      "Epoch 79/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 720.4062 - val_loss: 711.9093\n",
      "Epoch 80/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 715.6717 - val_loss: 720.7181\n",
      "Epoch 81/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 717.2685 - val_loss: 714.2731\n",
      "Epoch 82/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 715.7009 - val_loss: 714.2522\n",
      "Epoch 83/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 713.8331 - val_loss: 718.7371\n",
      "Epoch 84/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 714.9574 - val_loss: 709.4457\n",
      "Epoch 85/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 714.1855 - val_loss: 708.8420\n",
      "Epoch 86/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 712.1892 - val_loss: 706.3688\n",
      "Epoch 87/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 711.6957 - val_loss: 706.7541\n",
      "Epoch 88/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 710.5244 - val_loss: 713.2626\n",
      "Epoch 89/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 710.0555 - val_loss: 708.2740\n",
      "Epoch 90/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 711.2974 - val_loss: 704.2852\n",
      "Epoch 91/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 707.4670 - val_loss: 705.7856\n",
      "Epoch 92/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 707.4078 - val_loss: 703.6315\n",
      "Epoch 93/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 706.8015 - val_loss: 704.3139\n",
      "Epoch 94/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 706.0671 - val_loss: 702.9648\n",
      "Epoch 95/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 705.9436 - val_loss: 710.5797\n",
      "Epoch 96/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 710.4432 - val_loss: 703.6591\n",
      "Epoch 97/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 704.5983 - val_loss: 700.3613\n",
      "Epoch 98/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 704.8581 - val_loss: 701.7076\n",
      "Epoch 99/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 701.8804 - val_loss: 699.6144\n",
      "Epoch 100/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 701.2847 - val_loss: 697.7620\n"
     ]
    }
   ],
   "source": [
    "history2 = cnn3.fit(processed_train_data, processed_train_targets,\n",
    "                    validation_data=(processed_val_data, processed_val_targets),\n",
    "                    epochs=100,\n",
    "                   batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "r6ui6l2DAnL3",
    "outputId": "015cc174-0791-4b92-d011-f9ed49f4b364"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6c045f57d16e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplot_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'history2' is not defined"
     ]
    }
   ],
   "source": [
    "# plot history\n",
    "def plot_loss(fit_history):\n",
    "    plt.figure(figsize=(13,5))\n",
    "    plt.plot(range(1, len(fit_history.history['loss'])+1), fit_history.history['loss'], label='train')\n",
    "    plt.plot(range(1, len(fit_history.history['val_loss'])+1), fit_history.history['val_loss'], label='validate')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "2p_airjLAnL4",
    "outputId": "86be119c-881a-45f8-9adf-ad94bb6db779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_15 (Conv1D)          (None, 28, 32)            1376      \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 14, 32)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_16 (Conv1D)          (None, 12, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPoolin  (None, 6, 64)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 4, 32)             6176      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPoolin  (None, 2, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,760\n",
      "Trainable params: 13,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "-rWWmBYnAnL4",
    "outputId": "08328218-c795-4ad3-cfa7-499ad82884b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "hope_train_3 = cnn3.predict(processed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Rk1Y_bHlAnL4",
    "outputId": "bf48d9f3-bca9-41a1-aaef-2ca6d97f57ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "hope_test_3 = cnn3.predict(processed_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "tQdLKO35AnL4",
    "outputId": "38bd5629-0af9-4405-fa51-f09b17011665"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_reg_model =SVR()\n",
    "best_reg_model.fit(hope_train_3,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "Q9yyHsc-AnL5"
   },
   "outputs": [],
   "source": [
    "y_pred =best_reg_model.predict(hope_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "K8m69Y0_AnL5",
    "outputId": "33988210-aac2-4973-9de1-963da1c7b8db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set RMSE:14.062495429169035, R2:0.886670813367446\n"
     ]
    }
   ],
   "source": [
    "evaluate(processed_train_targets, y_pred, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "cNIXn2Z9AnL5"
   },
   "outputs": [],
   "source": [
    "y_pred_test =best_reg_model.predict(hope_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "WifOPdlmAnL5",
    "outputId": "3cf1390d-144f-4005-b0a9-aa88a94b80f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  16.961614766029633\n"
     ]
    }
   ],
   "source": [
    "preds_for_each_engine = np.split(y_pred_test, np.cumsum(num_test_windows_list)[:-1])\n",
    "mean_pred_for_each_engine = [np.average(ruls_for_each_engine,weights=np.repeat(1/num_windows, num_windows),axis=0)\n",
    "                             for ruls_for_each_engine, num_windows in zip(preds_for_each_engine, num_test_windows_list)]\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(true_rul, mean_pred_for_each_engine))\n",
    "print(\"RMSE: \", RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "sCF8xujBAnL6",
    "outputId": "bd98edca-b5e5-414f-8c8b-104d284ffa48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Taking only last examples):  17.065553989462078\n"
     ]
    }
   ],
   "source": [
    "indices_of_last_examples = np.cumsum(num_test_windows_list) - 1\n",
    "preds_for_last_example = np.concatenate(preds_for_each_engine)[indices_of_last_examples]\n",
    "\n",
    "RMSE_new = np.sqrt(mean_squared_error(true_rul, preds_for_last_example))\n",
    "print(\"RMSE (Taking only last examples): \", RMSE_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkxrZe5kAnL6"
   },
   "outputs": [],
   "source": [
    "evaluate(true_rul,mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130
    },
    "id": "UX_VdF9EErNy",
    "outputId": "0c167d4d-491e-4d2b-9a59-e435ceff9ae3"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-454c71fbf909>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    ('read_csv', test_data=pd.read_csv(\"/content/drive/MyDrive/Project/data/test_FD001.txt\", sep= \"\\s+\", header = None, names=columns)),\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "   \n",
    "  \n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets\n",
    "\n",
    "\n",
    "\n",
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "  \n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "columns = [\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\"]\n",
    "columns_to_be_dropped =['id','op1','op2','op3', 'sensor1', 'sensor5', 'sensor6','sensor7','sensor10',\n",
    "                 'sensor16', 'sensor18', 'sensor19']\n",
    "\n",
    "window_length = 30\n",
    "shift = 1\n",
    "early_rul = 125\n",
    "num_test_windows = 5\n",
    "\n",
    "data_preprocessing = Pipeline([\n",
    "    ('read_csv', test_data=pd.read_csv(\"/content/drive/MyDrive/Project/data/test_FD001.txt\", sep= \"\\s+\", header = None, names=columns)),\n",
    "    ('drop_columns', pd.DataFrame(data=test_data.drop(columns=columns_to_be_dropped))),\n",
    "    ('scaler', MinMaxScaler(feature_range=(-1,1))),\n",
    "    ('process_test_data', process_test_data(test_data, window_length, shift, num_test_windows))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "SlAI0fStIWr-",
    "outputId": "268d9b04-1105-4616-bc46-fc0ddb7f8aaf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-0a40810e7e42>:55: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0a40810e7e42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m pipe = Pipeline([\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'scaler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'process_test_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprocess_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_test_windows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m ])\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-0a40810e7e42>\u001b[0m in \u001b[0;36mprocess_test_data\u001b[0;34m(test_data_for_an_engine, window_length, shift, num_test_windows)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mrequired_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_test_windows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mshift\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n\u001b[0m\u001b[1;32m     65\u001b[0m                                                                           \u001b[0mtarget_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                                                           window_length = window_length, shift = shift)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3359\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(-34, None, None), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define custom processing functions\n",
    "\n",
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "   \n",
    "  \n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets\n",
    "\n",
    "\n",
    "\n",
    "def process_test_data(test_data_for_an_engine, window_length, shift, num_test_windows = 1):\n",
    "   \n",
    "    max_num_test_batches = np.int(np.floor((len(test_data_for_an_engine) - window_length)/shift)) + 1\n",
    "    if max_num_test_batches < num_test_windows:\n",
    "        required_len = (max_num_test_batches -1)* shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, max_num_test_batches\n",
    "    else:\n",
    "        required_len = (num_test_windows - 1) * shift + window_length\n",
    "        batched_test_data_for_an_engine = process_input_data_with_targets(test_data_for_an_engine[-required_len:, :],\n",
    "                                                                          target_data = None,\n",
    "                                                                          window_length = window_length, shift = shift)\n",
    "        return batched_test_data_for_an_engine, num_test_windows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the pipeline\n",
    "columns=[\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\",\"sensor6\",\"sensor7\",\"sensor8\",\n",
    "         \"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\",\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "         ,\"sensor20\",\"sensor21\"]\n",
    "\n",
    "test_data =pd.read_csv(\"/content/drive/MyDrive/Project/data/test_FD001.txt\", sep= \"\\s+\", header = None,names=columns) \n",
    "true_rul = pd.read_csv(\"/content/drive/MyDrive/Project/data/RUL_FD001.txt\", sep= \"\\s+\", header = None) \n",
    "\n",
    "window_length = 30\n",
    "early_rul = 125            \n",
    "processed_train_data = []\n",
    "num_test_windows = 5     \n",
    "processed_test_data = []\n",
    "num_test_windows_list = []\n",
    "\n",
    "columns_to_be_dropped =['id','op1','op2','op3', 'sensor1', 'sensor5', 'sensor6','sensor7','sensor10',\n",
    "                 'sensor16', 'sensor18', 'sensor19']\n",
    "\n",
    "test_data_first_column = test_data['id']\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', MinMaxScaler(feature_range = (-1,1))),\n",
    "    ('process_test_data',process_test_data(test_data, window_length, shift, num_test_windows))\n",
    "])\n",
    "\n",
    "processed_test_data, num_test_windows_list = pipe.fit_transform(test_data)\n",
    "processed_test_data = np.concatenate(processed_test_data)\n",
    "true_rul = true_rul[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SqL0O9FTMW_b"
   },
   "outputs": [],
   "source": [
    "def process_input_data_with_targets(input_data, target_data = None, window_length = 1, shift = 1):\n",
    "    \"\"\"Depending on values of window_length and shift, this function generates batchs of data and targets \n",
    "    from input_data and target_data.\n",
    "    \n",
    "    Number of batches = np.floor((len(input_data) - window_length)/shift) + 1\n",
    "    \n",
    "    **We don't check input dimensions uisng exception handling. So readers should be careful while using these\n",
    "    functions. If input data are not of desired dimension, either error occurs or something undesirable is \n",
    "    produced as output.**\n",
    "    \n",
    "    Arguments:\n",
    "        input_data: input data to function (Must be 2 dimensional)\n",
    "        target_data: input rul values (Must be 1D array)s\n",
    "        window_length: window length of data\n",
    "        shift: Distance by which the window moves for next batch. This is closely related to overlap\n",
    "               between data. For example, if window length is 30 and shift is 1, there is an overlap of \n",
    "               29 data points between two consecutive batches.\n",
    "        \n",
    "    \"\"\"\n",
    "    num_batches = np.int(np.floor((len(input_data) - window_length)/shift)) + 1\n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                  num_features)\n",
    "    if target_data is None:\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        return output_data\n",
    "    else:\n",
    "        output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "        for batch in range(num_batches):\n",
    "            output_data[batch,:,:] = input_data[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "            output_targets[batch] = target_data[(shift*batch + (window_length-1))]\n",
    "        return output_data, output_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OaQfY1UlIfKE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
